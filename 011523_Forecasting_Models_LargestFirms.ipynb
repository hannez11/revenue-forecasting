{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mstats\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error#, mean_absolute_percentage_error\n",
    "import category_encoders\n",
    "\n",
    "import lightgbm\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', 500) \n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# print multiple outputs in one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter_guided</th>\n",
       "      <th>quarter_previous</th>\n",
       "      <th>date_guided</th>\n",
       "      <th>date_previous</th>\n",
       "      <th>actuals_announcement_date</th>\n",
       "      <th>guidance_annoucement_date</th>\n",
       "      <th>isin</th>\n",
       "      <th>firm_observations</th>\n",
       "      <th>firm_id</th>\n",
       "      <th>sic_division</th>\n",
       "      <th>fama_french_industry</th>\n",
       "      <th>firm_id_cat</th>\n",
       "      <th>sic_division_cat</th>\n",
       "      <th>fama_french_industry_cat</th>\n",
       "      <th>quarter_fama_industry_cat</th>\n",
       "      <th>year_fama_industry_cat</th>\n",
       "      <th>quarter_previous_cat</th>\n",
       "      <th>year_cat</th>\n",
       "      <th>actual_revenue</th>\n",
       "      <th>revenue_guidance_average</th>\n",
       "      <th>revenue_guidance_error_adjusted</th>\n",
       "      <th>revenue_guidance_range</th>\n",
       "      <th>revenue_guidance_error_previous_rel</th>\n",
       "      <th>analyst_mean_guidance_date</th>\n",
       "      <th>revenue_prev</th>\n",
       "      <th>revenue_prev2</th>\n",
       "      <th>revenue_prev3</th>\n",
       "      <th>revenue_prev3_change</th>\n",
       "      <th>revenue_prev2_change</th>\n",
       "      <th>ebit</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>net_income</th>\n",
       "      <th>cogs</th>\n",
       "      <th>sga</th>\n",
       "      <th>depreciation_amortization</th>\n",
       "      <th>assets</th>\n",
       "      <th>cash_eq</th>\n",
       "      <th>receivables</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>total_equity</th>\n",
       "      <th>nwc</th>\n",
       "      <th>change_nwc</th>\n",
       "      <th>capex</th>\n",
       "      <th>free_cash_flow</th>\n",
       "      <th>cash_from_invest</th>\n",
       "      <th>cash_from_finance</th>\n",
       "      <th>cash_from_oper</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>price_at_guidance</th>\n",
       "      <th>price_15days</th>\n",
       "      <th>price_40days</th>\n",
       "      <th>price_60days</th>\n",
       "      <th>price_180days</th>\n",
       "      <th>price_180days_change</th>\n",
       "      <th>price_60days_change</th>\n",
       "      <th>price_40days_change</th>\n",
       "      <th>price_15days_change</th>\n",
       "      <th>price_vola_3month</th>\n",
       "      <th>price_vola_6month</th>\n",
       "      <th>beta_russell_60days</th>\n",
       "      <th>short_interest_at_guidance</th>\n",
       "      <th>short_interest_15</th>\n",
       "      <th>short_interest_60</th>\n",
       "      <th>short_interest_180</th>\n",
       "      <th>short_interest_180_change</th>\n",
       "      <th>short_interest_60_change</th>\n",
       "      <th>short_interest_15_change</th>\n",
       "      <th>goodwill</th>\n",
       "      <th>operating_income</th>\n",
       "      <th>book_value_share</th>\n",
       "      <th>real_gdp_growth</th>\n",
       "      <th>ebit_margin</th>\n",
       "      <th>ebitda_margin</th>\n",
       "      <th>net_income_margin</th>\n",
       "      <th>roic_an</th>\n",
       "      <th>return_on_equity</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>nwc_assets</th>\n",
       "      <th>capex_assets_ratio</th>\n",
       "      <th>restructuring_charges_many_zeros</th>\n",
       "      <th>rd_many_zeros</th>\n",
       "      <th>selling_marketing_many_zeros</th>\n",
       "      <th>inventory_turnover_many_zeros</th>\n",
       "      <th>warranty_liablities_many_zeros</th>\n",
       "      <th>total_dividends_many_zeros</th>\n",
       "      <th>goodwill_impairment_many_zeros</th>\n",
       "      <th>restricted_cash_many_zeros</th>\n",
       "      <th>gain_on_sale_assets_many_zeros</th>\n",
       "      <th>gain_on_sale_invest_many_zeros</th>\n",
       "      <th>warranty_liabilities_many_zeros</th>\n",
       "      <th>asset_writedown_many_zeros</th>\n",
       "      <th>inventory_many_zeros</th>\n",
       "      <th>raw_materials_inventory_many_zeros</th>\n",
       "      <th>work_in_progress_inventory_many_zeros</th>\n",
       "      <th>finished_goods_inventory_many_zeros</th>\n",
       "      <th>change_in_inventories_many_zeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001Q4</td>\n",
       "      <td>2001Q3</td>\n",
       "      <td>2001-12-31</td>\n",
       "      <td>2001-09-30</td>\n",
       "      <td>2001-10-25</td>\n",
       "      <td>2001-12-19</td>\n",
       "      <td>US5184391044</td>\n",
       "      <td>33</td>\n",
       "      <td>1073</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1073</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2001Q49</td>\n",
       "      <td>20019</td>\n",
       "      <td>3</td>\n",
       "      <td>2001</td>\n",
       "      <td>1298.200</td>\n",
       "      <td>1272.226000</td>\n",
       "      <td>1253.693145</td>\n",
       "      <td>12.91600</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>1323.150</td>\n",
       "      <td>1194.800</td>\n",
       "      <td>1047.200</td>\n",
       "      <td>1103.500</td>\n",
       "      <td>0.082737</td>\n",
       "      <td>0.140947</td>\n",
       "      <td>152.900</td>\n",
       "      <td>190.600</td>\n",
       "      <td>845.500</td>\n",
       "      <td>76.500</td>\n",
       "      <td>349.300</td>\n",
       "      <td>692.600</td>\n",
       "      <td>37.700</td>\n",
       "      <td>3300.500</td>\n",
       "      <td>157.400</td>\n",
       "      <td>794.100</td>\n",
       "      <td>1524.800</td>\n",
       "      <td>430.900</td>\n",
       "      <td>1775.700</td>\n",
       "      <td>785.500</td>\n",
       "      <td>244.200</td>\n",
       "      <td>-50.100</td>\n",
       "      <td>-165.41250</td>\n",
       "      <td>-58.000</td>\n",
       "      <td>-38.600</td>\n",
       "      <td>-104.400</td>\n",
       "      <td>7914.22921</td>\n",
       "      <td>15.99501</td>\n",
       "      <td>16.65000</td>\n",
       "      <td>13.12443</td>\n",
       "      <td>16.98001</td>\n",
       "      <td>20.30001</td>\n",
       "      <td>-0.212069</td>\n",
       "      <td>-0.058009</td>\n",
       "      <td>0.218720</td>\n",
       "      <td>-0.039339</td>\n",
       "      <td>32.7232</td>\n",
       "      <td>31.1500</td>\n",
       "      <td>1.02641</td>\n",
       "      <td>2.48016</td>\n",
       "      <td>2.48016</td>\n",
       "      <td>2.45677</td>\n",
       "      <td>2.81850</td>\n",
       "      <td>-0.120043</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>708.000</td>\n",
       "      <td>152.900</td>\n",
       "      <td>2.97741</td>\n",
       "      <td>3.06350</td>\n",
       "      <td>-3.1189</td>\n",
       "      <td>3.6608</td>\n",
       "      <td>-3.4009</td>\n",
       "      <td>-2.7508</td>\n",
       "      <td>-2.7508</td>\n",
       "      <td>0.252261</td>\n",
       "      <td>-0.054954</td>\n",
       "      <td>-0.011531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.18620</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>647.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-7.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001Q4</td>\n",
       "      <td>2001Q3</td>\n",
       "      <td>2001-12-28</td>\n",
       "      <td>2001-09-28</td>\n",
       "      <td>2001-10-25</td>\n",
       "      <td>2001-12-21</td>\n",
       "      <td>US9581021055</td>\n",
       "      <td>60</td>\n",
       "      <td>1985</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>1985</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>2001Q435</td>\n",
       "      <td>200135</td>\n",
       "      <td>3</td>\n",
       "      <td>2001</td>\n",
       "      <td>574.670</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>537.060840</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>471.000</td>\n",
       "      <td>440.943</td>\n",
       "      <td>455.733</td>\n",
       "      <td>511.723</td>\n",
       "      <td>-0.138317</td>\n",
       "      <td>-0.032453</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>11.054</td>\n",
       "      <td>56.007</td>\n",
       "      <td>20.518</td>\n",
       "      <td>384.936</td>\n",
       "      <td>27.368</td>\n",
       "      <td>11.260</td>\n",
       "      <td>619.445</td>\n",
       "      <td>200.582</td>\n",
       "      <td>212.085</td>\n",
       "      <td>582.320</td>\n",
       "      <td>113.974</td>\n",
       "      <td>37.125</td>\n",
       "      <td>-130.720</td>\n",
       "      <td>-8.501</td>\n",
       "      <td>-12.013</td>\n",
       "      <td>6.35050</td>\n",
       "      <td>-12.013</td>\n",
       "      <td>1.562</td>\n",
       "      <td>43.451</td>\n",
       "      <td>405.57546</td>\n",
       "      <td>6.10000</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>1.74207</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>3.38000</td>\n",
       "      <td>0.804734</td>\n",
       "      <td>0.948882</td>\n",
       "      <td>2.501581</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>101.2625</td>\n",
       "      <td>82.7647</td>\n",
       "      <td>0.23004</td>\n",
       "      <td>2.82340</td>\n",
       "      <td>2.82340</td>\n",
       "      <td>2.34647</td>\n",
       "      <td>1.85761</td>\n",
       "      <td>0.519910</td>\n",
       "      <td>0.203254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.14804</td>\n",
       "      <td>4.95569</td>\n",
       "      <td>-46.2681</td>\n",
       "      <td>-36.2136</td>\n",
       "      <td>290.2417</td>\n",
       "      <td>69.0232</td>\n",
       "      <td>80.8832</td>\n",
       "      <td>0.491158</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.845</td>\n",
       "      <td>0.000</td>\n",
       "      <td>19.83592</td>\n",
       "      <td>30.297</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>30.297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.343</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002Q1</td>\n",
       "      <td>2001Q4</td>\n",
       "      <td>2002-03-31</td>\n",
       "      <td>2001-12-31</td>\n",
       "      <td>2002-02-06</td>\n",
       "      <td>2002-02-06</td>\n",
       "      <td>US00246W1036</td>\n",
       "      <td>78</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>2002Q137</td>\n",
       "      <td>200237</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>11.739</td>\n",
       "      <td>15.755275</td>\n",
       "      <td>15.525764</td>\n",
       "      <td>0.76855</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>14.785</td>\n",
       "      <td>15.371</td>\n",
       "      <td>22.783</td>\n",
       "      <td>41.272</td>\n",
       "      <td>-0.627568</td>\n",
       "      <td>-0.325330</td>\n",
       "      <td>-6.272</td>\n",
       "      <td>-3.633</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-13.844</td>\n",
       "      <td>15.891</td>\n",
       "      <td>4.382</td>\n",
       "      <td>2.639</td>\n",
       "      <td>243.359</td>\n",
       "      <td>37.538</td>\n",
       "      <td>15.684</td>\n",
       "      <td>57.037</td>\n",
       "      <td>31.052</td>\n",
       "      <td>186.322</td>\n",
       "      <td>68.792</td>\n",
       "      <td>4.510</td>\n",
       "      <td>-1.513</td>\n",
       "      <td>-7.55750</td>\n",
       "      <td>-1.663</td>\n",
       "      <td>-1.909</td>\n",
       "      <td>2.388</td>\n",
       "      <td>322.67766</td>\n",
       "      <td>9.83000</td>\n",
       "      <td>11.60000</td>\n",
       "      <td>14.43000</td>\n",
       "      <td>15.57000</td>\n",
       "      <td>21.17000</td>\n",
       "      <td>-0.535664</td>\n",
       "      <td>-0.368658</td>\n",
       "      <td>-0.318780</td>\n",
       "      <td>-0.152586</td>\n",
       "      <td>68.8823</td>\n",
       "      <td>81.6801</td>\n",
       "      <td>4.59181</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.107</td>\n",
       "      <td>-6.272</td>\n",
       "      <td>8.16647</td>\n",
       "      <td>2.53205</td>\n",
       "      <td>1.8938</td>\n",
       "      <td>8.5154</td>\n",
       "      <td>1.9379</td>\n",
       "      <td>3.6976</td>\n",
       "      <td>3.6976</td>\n",
       "      <td>0.025342</td>\n",
       "      <td>-0.070007</td>\n",
       "      <td>-0.054175</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.11394</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.636</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.587</td>\n",
       "      <td>21.308</td>\n",
       "      <td>30.265</td>\n",
       "      <td>17.368</td>\n",
       "      <td>2.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2002Q1</td>\n",
       "      <td>2001Q4</td>\n",
       "      <td>2002-03-01</td>\n",
       "      <td>2001-11-30</td>\n",
       "      <td>2001-12-13</td>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>US00724F1012</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>2002Q136</td>\n",
       "      <td>200236</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>267.896</td>\n",
       "      <td>272.500000</td>\n",
       "      <td>268.530420</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>274.944</td>\n",
       "      <td>264.540</td>\n",
       "      <td>292.118</td>\n",
       "      <td>344.093</td>\n",
       "      <td>-0.231196</td>\n",
       "      <td>-0.094407</td>\n",
       "      <td>64.324</td>\n",
       "      <td>78.514</td>\n",
       "      <td>245.505</td>\n",
       "      <td>34.289</td>\n",
       "      <td>19.035</td>\n",
       "      <td>122.982</td>\n",
       "      <td>14.190</td>\n",
       "      <td>932.173</td>\n",
       "      <td>218.662</td>\n",
       "      <td>143.955</td>\n",
       "      <td>315.201</td>\n",
       "      <td>0.000</td>\n",
       "      <td>616.972</td>\n",
       "      <td>-127.900</td>\n",
       "      <td>-44.809</td>\n",
       "      <td>-8.826</td>\n",
       "      <td>93.80788</td>\n",
       "      <td>-93.729</td>\n",
       "      <td>-108.479</td>\n",
       "      <td>128.611</td>\n",
       "      <td>7609.10582</td>\n",
       "      <td>16.85000</td>\n",
       "      <td>17.55001</td>\n",
       "      <td>15.96221</td>\n",
       "      <td>16.04000</td>\n",
       "      <td>18.97000</td>\n",
       "      <td>-0.111755</td>\n",
       "      <td>0.050499</td>\n",
       "      <td>0.055618</td>\n",
       "      <td>-0.039887</td>\n",
       "      <td>63.5223</td>\n",
       "      <td>63.4337</td>\n",
       "      <td>2.33561</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>64.324</td>\n",
       "      <td>1.30704</td>\n",
       "      <td>2.98267</td>\n",
       "      <td>8.4279</td>\n",
       "      <td>10.9573</td>\n",
       "      <td>3.5266</td>\n",
       "      <td>6.4260</td>\n",
       "      <td>10.6604</td>\n",
       "      <td>0.195697</td>\n",
       "      <td>0.174252</td>\n",
       "      <td>-0.002365</td>\n",
       "      <td>-12.063</td>\n",
       "      <td>54.649</td>\n",
       "      <td>94.831</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2002Q1</td>\n",
       "      <td>2001Q4</td>\n",
       "      <td>2002-03-31</td>\n",
       "      <td>2001-12-30</td>\n",
       "      <td>2002-01-16</td>\n",
       "      <td>2002-02-27</td>\n",
       "      <td>US0079031078</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>2002Q137</td>\n",
       "      <td>200237</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>902.073</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>886.889460</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>910.200</td>\n",
       "      <td>951.873</td>\n",
       "      <td>765.870</td>\n",
       "      <td>985.264</td>\n",
       "      <td>-0.033890</td>\n",
       "      <td>0.242865</td>\n",
       "      <td>-17.344</td>\n",
       "      <td>133.134</td>\n",
       "      <td>307.211</td>\n",
       "      <td>-15.842</td>\n",
       "      <td>644.662</td>\n",
       "      <td>163.684</td>\n",
       "      <td>150.478</td>\n",
       "      <td>5647.242</td>\n",
       "      <td>427.288</td>\n",
       "      <td>659.783</td>\n",
       "      <td>2092.187</td>\n",
       "      <td>1004.643</td>\n",
       "      <td>3555.055</td>\n",
       "      <td>500.873</td>\n",
       "      <td>-15.277</td>\n",
       "      <td>-136.974</td>\n",
       "      <td>12.99975</td>\n",
       "      <td>-87.174</td>\n",
       "      <td>10.200</td>\n",
       "      <td>111.567</td>\n",
       "      <td>5566.37011</td>\n",
       "      <td>14.02000</td>\n",
       "      <td>15.12000</td>\n",
       "      <td>16.38000</td>\n",
       "      <td>16.38000</td>\n",
       "      <td>13.55000</td>\n",
       "      <td>0.034686</td>\n",
       "      <td>-0.144078</td>\n",
       "      <td>-0.144078</td>\n",
       "      <td>-0.072751</td>\n",
       "      <td>74.1238</td>\n",
       "      <td>90.4538</td>\n",
       "      <td>0.88734</td>\n",
       "      <td>5.81596</td>\n",
       "      <td>5.81596</td>\n",
       "      <td>3.44227</td>\n",
       "      <td>2.82024</td>\n",
       "      <td>1.062222</td>\n",
       "      <td>0.689571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-17.344</td>\n",
       "      <td>10.44060</td>\n",
       "      <td>3.26198</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.184441</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>160.871</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.21696</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.474</td>\n",
       "      <td>26.489</td>\n",
       "      <td>236.679</td>\n",
       "      <td>117.306</td>\n",
       "      <td>75.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quarter_guided quarter_previous date_guided date_previous  \\\n",
       "3         2001Q4           2001Q3  2001-12-31    2001-09-30   \n",
       "5         2001Q4           2001Q3  2001-12-28    2001-09-28   \n",
       "6         2002Q1           2001Q4  2002-03-31    2001-12-31   \n",
       "7         2002Q1           2001Q4  2002-03-01    2001-11-30   \n",
       "8         2002Q1           2001Q4  2002-03-31    2001-12-30   \n",
       "\n",
       "  actuals_announcement_date guidance_annoucement_date          isin  \\\n",
       "3                2001-10-25                2001-12-19  US5184391044   \n",
       "5                2001-10-25                2001-12-21  US9581021055   \n",
       "6                2002-02-06                2002-02-06  US00246W1036   \n",
       "7                2001-12-13                2002-01-31  US00724F1012   \n",
       "8                2002-01-16                2002-02-27  US0079031078   \n",
       "\n",
       "   firm_observations  firm_id  sic_division  fama_french_industry firm_id_cat  \\\n",
       "3                 33     1073             3                     9        1073   \n",
       "5                 60     1985             3                    35        1985   \n",
       "6                 78       59             3                    37          59   \n",
       "7                 78       84             6                    36          84   \n",
       "8                 60       90             3                    37          90   \n",
       "\n",
       "  sic_division_cat fama_french_industry_cat quarter_fama_industry_cat  \\\n",
       "3                3                        9                   2001Q49   \n",
       "5                3                       35                  2001Q435   \n",
       "6                3                       37                  2002Q137   \n",
       "7                6                       36                  2002Q136   \n",
       "8                3                       37                  2002Q137   \n",
       "\n",
       "  year_fama_industry_cat quarter_previous_cat year_cat  actual_revenue  \\\n",
       "3                  20019                    3     2001        1298.200   \n",
       "5                 200135                    3     2001         574.670   \n",
       "6                 200237                    4     2002          11.739   \n",
       "7                 200236                    4     2002         267.896   \n",
       "8                 200237                    4     2002         902.073   \n",
       "\n",
       "   revenue_guidance_average  revenue_guidance_error_adjusted  \\\n",
       "3               1272.226000                      1253.693145   \n",
       "5                545.000000                       537.060840   \n",
       "6                 15.755275                        15.525764   \n",
       "7                272.500000                       268.530420   \n",
       "8                900.000000                       886.889460   \n",
       "\n",
       "   revenue_guidance_range  revenue_guidance_error_previous_rel  \\\n",
       "3                12.91600                            -0.014567   \n",
       "5                10.00000                            -0.014567   \n",
       "6                 0.76855                            -0.014567   \n",
       "7                15.00000                            -0.014567   \n",
       "8                 0.00000                            -0.014567   \n",
       "\n",
       "   analyst_mean_guidance_date  revenue_prev  revenue_prev2  revenue_prev3  \\\n",
       "3                    1323.150      1194.800       1047.200       1103.500   \n",
       "5                     471.000       440.943        455.733        511.723   \n",
       "6                      14.785        15.371         22.783         41.272   \n",
       "7                     274.944       264.540        292.118        344.093   \n",
       "8                     910.200       951.873        765.870        985.264   \n",
       "\n",
       "   revenue_prev3_change  revenue_prev2_change     ebit   ebitda  gross_profit  \\\n",
       "3              0.082737              0.140947  152.900  190.600       845.500   \n",
       "5             -0.138317             -0.032453   -0.206   11.054        56.007   \n",
       "6             -0.627568             -0.325330   -6.272   -3.633        -0.520   \n",
       "7             -0.231196             -0.094407   64.324   78.514       245.505   \n",
       "8             -0.033890              0.242865  -17.344  133.134       307.211   \n",
       "\n",
       "   net_income     cogs      sga  depreciation_amortization    assets  cash_eq  \\\n",
       "3      76.500  349.300  692.600                     37.700  3300.500  157.400   \n",
       "5      20.518  384.936   27.368                     11.260   619.445  200.582   \n",
       "6     -13.844   15.891    4.382                      2.639   243.359   37.538   \n",
       "7      34.289   19.035  122.982                     14.190   932.173  218.662   \n",
       "8     -15.842  644.662  163.684                    150.478  5647.242  427.288   \n",
       "\n",
       "   receivables  liabilities  total_debt  total_equity      nwc  change_nwc  \\\n",
       "3      794.100     1524.800     430.900      1775.700  785.500     244.200   \n",
       "5      212.085      582.320     113.974        37.125 -130.720      -8.501   \n",
       "6       15.684       57.037      31.052       186.322   68.792       4.510   \n",
       "7      143.955      315.201       0.000       616.972 -127.900     -44.809   \n",
       "8      659.783     2092.187    1004.643      3555.055  500.873     -15.277   \n",
       "\n",
       "     capex  free_cash_flow  cash_from_invest  cash_from_finance  \\\n",
       "3  -50.100      -165.41250           -58.000            -38.600   \n",
       "5  -12.013         6.35050           -12.013              1.562   \n",
       "6   -1.513        -7.55750            -1.663             -1.909   \n",
       "7   -8.826        93.80788           -93.729           -108.479   \n",
       "8 -136.974        12.99975           -87.174             10.200   \n",
       "\n",
       "   cash_from_oper   marketcap  price_at_guidance  price_15days  price_40days  \\\n",
       "3        -104.400  7914.22921           15.99501      16.65000      13.12443   \n",
       "5          43.451   405.57546            6.10000       5.25000       1.74207   \n",
       "6           2.388   322.67766            9.83000      11.60000      14.43000   \n",
       "7         128.611  7609.10582           16.85000      17.55001      15.96221   \n",
       "8         111.567  5566.37011           14.02000      15.12000      16.38000   \n",
       "\n",
       "   price_60days  price_180days  price_180days_change  price_60days_change  \\\n",
       "3      16.98001       20.30001             -0.212069            -0.058009   \n",
       "5       3.13000        3.38000              0.804734             0.948882   \n",
       "6      15.57000       21.17000             -0.535664            -0.368658   \n",
       "7      16.04000       18.97000             -0.111755             0.050499   \n",
       "8      16.38000       13.55000              0.034686            -0.144078   \n",
       "\n",
       "   price_40days_change  price_15days_change  price_vola_3month  \\\n",
       "3             0.218720            -0.039339            32.7232   \n",
       "5             2.501581             0.161905           101.2625   \n",
       "6            -0.318780            -0.152586            68.8823   \n",
       "7             0.055618            -0.039887            63.5223   \n",
       "8            -0.144078            -0.072751            74.1238   \n",
       "\n",
       "   price_vola_6month  beta_russell_60days  short_interest_at_guidance  \\\n",
       "3            31.1500              1.02641                     2.48016   \n",
       "5            82.7647              0.23004                     2.82340   \n",
       "6            81.6801              4.59181                     0.00000   \n",
       "7            63.4337              2.33561                     0.00000   \n",
       "8            90.4538              0.88734                     5.81596   \n",
       "\n",
       "   short_interest_15  short_interest_60  short_interest_180  \\\n",
       "3            2.48016            2.45677             2.81850   \n",
       "5            2.82340            2.34647             1.85761   \n",
       "6            0.00000            0.00000             0.00000   \n",
       "7            0.00000            0.00000             0.00000   \n",
       "8            5.81596            3.44227             2.82024   \n",
       "\n",
       "   short_interest_180_change  short_interest_60_change  \\\n",
       "3                  -0.120043                  0.009521   \n",
       "5                   0.519910                  0.203254   \n",
       "6                   0.000000                  0.000000   \n",
       "7                   0.000000                  0.000000   \n",
       "8                   1.062222                  0.689571   \n",
       "\n",
       "   short_interest_15_change  goodwill  operating_income  book_value_share  \\\n",
       "3                       0.0   708.000           152.900           2.97741   \n",
       "5                       0.0     0.000            -0.206           0.14804   \n",
       "6                       0.0     1.107            -6.272           8.16647   \n",
       "7                       0.0     0.000            64.324           1.30704   \n",
       "8                       0.0     0.000           -17.344          10.44060   \n",
       "\n",
       "   real_gdp_growth  ebit_margin  ebitda_margin  net_income_margin  roic_an  \\\n",
       "3          3.06350      -3.1189         3.6608            -3.4009  -2.7508   \n",
       "5          4.95569     -46.2681       -36.2136           290.2417  69.0232   \n",
       "6          2.53205       1.8938         8.5154             1.9379   3.6976   \n",
       "7          2.98267       8.4279        10.9573             3.5266   6.4260   \n",
       "8          3.26198       0.0000         0.0000             0.0000   0.0000   \n",
       "\n",
       "   return_on_equity  cash_asset_ratio  nwc_assets  capex_assets_ratio  \\\n",
       "3           -2.7508          0.252261   -0.054954           -0.011531   \n",
       "5           80.8832          0.491158    0.014048           -0.000964   \n",
       "6            3.6976          0.025342   -0.070007           -0.054175   \n",
       "7           10.6604          0.195697    0.174252           -0.002365   \n",
       "8            0.0000          0.184441    0.000183            0.000000   \n",
       "\n",
       "   restructuring_charges_many_zeros  rd_many_zeros  \\\n",
       "3                             0.000          0.000   \n",
       "5                             0.000         28.845   \n",
       "6                             0.000          1.370   \n",
       "7                           -12.063         54.649   \n",
       "8                             0.000        160.871   \n",
       "\n",
       "   selling_marketing_many_zeros  inventory_turnover_many_zeros  \\\n",
       "3                         0.000                        2.18620   \n",
       "5                         0.000                       19.83592   \n",
       "6                         0.000                        1.11394   \n",
       "7                        94.831                        0.00000   \n",
       "8                         0.000                        6.21696   \n",
       "\n",
       "   warranty_liablities_many_zeros  total_dividends_many_zeros  \\\n",
       "3                           0.000                      0.1000   \n",
       "5                          30.297                      0.0000   \n",
       "6                           0.000                      0.0000   \n",
       "7                           0.000                      0.0252   \n",
       "8                           0.000                      0.0000   \n",
       "\n",
       "   goodwill_impairment_many_zeros  restricted_cash_many_zeros  \\\n",
       "3                             0.0                         0.0   \n",
       "5                             0.0                         0.0   \n",
       "6                             0.0                         0.0   \n",
       "7                             0.0                         0.0   \n",
       "8                             0.0                         0.0   \n",
       "\n",
       "   gain_on_sale_assets_many_zeros  gain_on_sale_invest_many_zeros  \\\n",
       "3                             0.0                           0.000   \n",
       "5                             0.0                           0.000   \n",
       "6                             0.0                         -15.636   \n",
       "7                             0.0                          -0.098   \n",
       "8                             0.0                          -5.000   \n",
       "\n",
       "   warranty_liabilities_many_zeros  asset_writedown_many_zeros  \\\n",
       "3                            0.000                         0.0   \n",
       "5                           30.297                         0.0   \n",
       "6                            0.000                         0.0   \n",
       "7                            0.000                         0.0   \n",
       "8                            0.000                         0.0   \n",
       "\n",
       "   inventory_many_zeros  raw_materials_inventory_many_zeros  \\\n",
       "3               647.900                               0.000   \n",
       "5                76.343                               0.000   \n",
       "6                55.587                              21.308   \n",
       "7                 0.000                               0.000   \n",
       "8               380.474                              26.489   \n",
       "\n",
       "   work_in_progress_inventory_many_zeros  finished_goods_inventory_many_zeros  \\\n",
       "3                                  0.000                                0.000   \n",
       "5                                  0.000                                0.000   \n",
       "6                                 30.265                               17.368   \n",
       "7                                  0.000                                0.000   \n",
       "8                                236.679                              117.306   \n",
       "\n",
       "   change_in_inventories_many_zeros  \n",
       "3                            -7.200  \n",
       "5                             2.562  \n",
       "6                             2.951  \n",
       "7                             0.000  \n",
       "8                            75.979  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(22220, 98)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.joinpath(Path.cwd().parent / '1 Data', \"011223_management_guidance.pkl\")\n",
    "df_raw = pd.read_pickle(path)\n",
    "\n",
    "df_raw.head()\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## winsorize float variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WinsorizeColumn(data, percentile):\n",
    "    mstats.winsorize(data, limits=[percentile, percentile], inplace = True)\n",
    "\n",
    "df.select_dtypes(include=[float]).describe().transpose()[2:5]\n",
    "\n",
    "float_columns = df.select_dtypes(include=[float]).columns.to_list() #[:10]\n",
    "\n",
    "for column in float_columns:\n",
    "    WinsorizeColumn(df[column], percentile=0.1)\n",
    "\n",
    "df.select_dtypes(include=[float]).describe().transpose()[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# execute train/test split before\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df_temp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([X_train, y_train], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# add y to calc prediction error\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df_temp[\u001b[39m\"\u001b[39m\u001b[39merror_train\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(df_temp[\u001b[39m\"\u001b[39m\u001b[39mactual_revenue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m-\u001b[39m pd\u001b[39m.\u001b[39mconcat([X_train, y_train], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m\"\u001b[39m\u001b[39mrevenue_guidance_average\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m# prediction error\u001b[39;00m\n\u001b[0;32m      6\u001b[0m error_train_std \u001b[39m=\u001b[39m df_temp\u001b[39m.\u001b[39mgroupby(\u001b[39m\"\u001b[39m\u001b[39mfirm_id\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m\"\u001b[39m\u001b[39merror_train\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstd()\u001b[39m.\u001b[39mto_dict() \u001b[39m# std by group\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# execute train/test split before\n",
    "\n",
    "df_temp = pd.concat([X_train, y_train], axis=1) # add y to calc prediction error\n",
    "df_temp[\"error_train\"] = np.abs(df_temp[\"actual_revenue\"] - pd.concat([X_train, y_train], axis=1)[\"revenue_guidance_average\"]) # prediction error\n",
    "\n",
    "error_train_std = df_temp.groupby(\"firm_id\")[\"error_train\"].std().to_dict() # std by group\n",
    "# map new var to category\n",
    "df_temp[\"error_train_std\"] = df_temp[\"firm_id\"].map(error_train_std) \n",
    "X_test[\"error_train_std\"] = X_test[\"firm_id\"].map(error_train_std)\n",
    "\n",
    "# drop temp vars\n",
    "X_train = df_temp.drop(columns=[\"actual_revenue\", \"error_train\", 'fama_french_industry_cat'])\n",
    "X_test = X_test.drop(columns=['fama_french_industry_cat'])\n",
    "\n",
    "# replace if category unknown in test set\n",
    "X_train, X_test = X_train.replace({np.nan: 0}), X_test.replace({np.nan: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale/encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## simplified version of target encoder\n",
    "def target_encoding(cat_columns, shrinking_factor=0):\n",
    "    global X_train, X_test, y_train, y_test\n",
    "\n",
    "    encoder = category_encoders.MEstimateEncoder(cols=cat_columns, m=shrinking_factor) # Higher value of m results into stronger shrinking.\n",
    "    # same as df[[\"actual_revenue\", \"fama_french_industry\"]][:18909].groupby(\"fama_french_industry\")[\"actual_revenue\"].mean().to_dict()\n",
    "\n",
    "    encoder.fit(X_train, y_train) # only based on the training data\n",
    "    X_train = encoder.transform(X_train)\n",
    "    X_test = encoder.transform(X_test)\n",
    "    # print(f\"Target encoded: {cat_columns}\" + \"\\n\")\n",
    "\n",
    "## standard scaling\n",
    "def standard_scaling():\n",
    "    global X_train, X_test\n",
    "    sc = StandardScaler().fit(X_train[forecast_feature + floats + categoricals_targetencode]) # scale based on training data\n",
    "    X_train[forecast_feature + floats + categoricals_targetencode] = sc.transform(X_train[forecast_feature + floats + categoricals_targetencode])\n",
    "    X_test[forecast_feature + floats + categoricals_targetencode] = sc.transform(X_test[forecast_feature + floats + categoricals_targetencode])\n",
    "\n",
    "## one hot encoding (same as onehotencode from scikit)\n",
    "def one_hot_encode():\n",
    "    global X\n",
    "    if len(categoricals) > 0:\n",
    "        columns_to_onehotencode = [x for x in X.select_dtypes(include=['category']).columns.to_list() if x not in categoricals_targetencode]\n",
    "        X = pd.get_dummies(X, columns=columns_to_onehotencode)\n",
    "        print(f\"one hot encoded: {columns_to_onehotencode}\")\n",
    "\n",
    "## imputing\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# Xtrain_sklearn=imp_mean.fit_transform(pd.DataFrame(X_train['age']))\n",
    "# Xtest_sklearn=imp_mean.fit_transform(pd.DataFrame(X_test['age']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manager/analyst accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manager_analyst_accuracy(actual_var, manager_var, analyst_var):\n",
    "    global X_manager_test, X_analyst_test, mae_manager_test, mae_analyst_test, mape_manager_test, mape_analyst_test, rmse_manager_test, rmse_analyst_test\n",
    "\n",
    "    # get manager/analyst forecast array for train/test indices\n",
    "    X_manager_train, X_analyst_train = df.iloc[indices_train, ][manager_var], df.iloc[indices_train, ][analyst_var]\n",
    "    X_manager_test, X_analyst_test = df.iloc[indices_test, ][manager_var], df.iloc[indices_test, ][analyst_var]\n",
    "\n",
    "    # get actual revenue\n",
    "    y_train, y_test = df.iloc[indices_train, ][actual_var], df.iloc[indices_test, ][actual_var]\n",
    "\n",
    "    # calculate accuarcy measures\n",
    "    # mean absolute error\n",
    "    mae_manager_train, mae_manager_test = round(mean_absolute_error(y_train, X_manager_train), 4), round(mean_absolute_error(y_test, X_manager_test), 4)\n",
    "    mae_analyst_train, mae_analyst_test = round(mean_absolute_error(y_train, X_analyst_train), 4), round(mean_absolute_error(y_test, X_analyst_test), 4)\n",
    "    # mean absolute percentage error\n",
    "    # mape_manager_train, mape_manager_test = round(mean_absolute_percentage_error(y_train, X_manager_train), 4), round(mean_absolute_percentage_error(y_test, X_manager_test), 4)\n",
    "    # mape_analyst_train, mape_analyst_test = round(mean_absolute_percentage_error(y_train, X_analyst_train), 4), round(mean_absolute_percentage_error(y_test, X_analyst_test), 4)\n",
    "    # root mean squared error\n",
    "    rmse_manager_train, rmse_manager_test = round(mean_squared_error(y_train, X_manager_train, squared=False), 4), round(mean_squared_error(y_test, X_manager_test, squared=False), 4)\n",
    "    rmse_analyst_train, rmse_analyst_test = round(mean_squared_error(y_train, X_analyst_train, squared=False), 4), round(mean_squared_error(y_test, X_analyst_test, squared=False), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to give more weights to observations that are further from the mean (i.e. if being “off” by 20 is more than twice as bad as being off by 10″) then it’s better to use the RMSE to measure error because the RMSE is more sensitive to observations that are further from the mean. RMSE -> normal distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(y_pred, print_results=True):\n",
    "    global mae_model_test, mape_model_test, rmse_model_test, ttest_model_manager, ttest_model_analyst\n",
    "\n",
    "    # mean absolute errors\n",
    "    mae_model_test = round(mean_absolute_error(y_test, y_pred), 4)\n",
    "    # mape_model_test = round(mean_absolute_percentage_error(y_test, y_pred), 4)\n",
    "    rmse_model_test = round(mean_squared_error(y_test, y_pred, squared=False), 4)\n",
    "\n",
    "    # t-test of the absolute error of each observation\n",
    "    ttest_model_manager = stats.ttest_ind(a=np.array(abs(y_pred-y_test)), b=np.array(abs(X_manager_test-y_test)), equal_var=False)\n",
    "    ttest_model_analyst = stats.ttest_ind(a=np.array(abs(y_pred-y_test)), b=np.array(abs(X_analyst_test-y_test)), equal_var=False)\n",
    "\n",
    "    if print_results == True:\n",
    "        print(\"\\n\" + \"**********\")\n",
    "        print(f\"model test MAE (RMSE): {mae_model_test} ({rmse_model_test})\")\n",
    "        print(f\"manager test MAE (RMSE): {mae_manager_test} ({rmse_manager_test})\")\n",
    "        print(f\"analyst test MAE (RMSE): {mae_analyst_test} ({rmse_analyst_test})\" + \"\\n\")\n",
    "        print(\"**********\")\n",
    "        print(f\"model vs manager: edge {round((mae_model_test-mae_manager_test)/mae_manager_test, 3)} | t-stat {round(ttest_model_manager[0], 3)} p-value {round(ttest_model_manager[1], 3)}\")\n",
    "        print(f\"model vs analyst: edge {round((mae_model_test-mae_analyst_test)/mae_analyst_test, 3)} | t-stat {round(ttest_model_analyst[0], 3)} p-value {round(ttest_model_analyst[1], 3)}\")\n",
    "        print(\"\\n\" + \"************************************\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tree models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_model(param, num_boost_round, features, log=3000):# setup train/test data\n",
    "    global bst, y_pred\n",
    "\n",
    "    train_data = lightgbm.Dataset(X_train, label=y_train, feature_name=features) # , categorical_feature=categorical_features: LightGBM uses the algorithm Fisher 1958 to handle categorical features. No need to specificy them, if dtype is Categorical\n",
    "    test_data = lightgbm.Dataset(X_test, label=y_test, reference=train_data)\n",
    "        \n",
    "    # train model\n",
    "    bst = lightgbm.train(param, train_data, num_boost_round, verbose_eval=log, valid_sets=test_data) #callbacks=[lightgbm.log_evaluation(100)]\n",
    "\n",
    "    # predict\n",
    "    y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "######################\n",
    "#https://lightgbm.readthedocs.io/en/v3.3.3/Parameters.html\n",
    "param = {\n",
    "    'verbose': -1,\n",
    "    'boosting': 'gbdt', # gbdt, rf, dart, goss\n",
    "    'objective': 'regression_l1',\n",
    "    'num_leaves': 20, \n",
    "    'learning_rate': 0.05,\n",
    "    'early_stopping_round': 100,\n",
    "    'metric': ['MAE'],\n",
    "    'first_metric_only': True,\n",
    "    'num_threads': 10\n",
    "    }\n",
    "\n",
    "param.update({'num_leaves': 5, 'learning_rate': 0.02, 'max_depth': 6, 'min_data_in_leaf': 8}) # manager without 10% highest rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb/rf/et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def rf_model():\n",
    "    global y_pred_rf\n",
    "    param_rf = {\n",
    "                \"n_estimators\": 281,\n",
    "                \"max_depth\": 36,\n",
    "                \"min_samples_leaf\": 1,\n",
    "                \"max_leaf_nodes\": None,\n",
    "                \"n_jobs\": -1,\n",
    "                \"random_state\": 123\n",
    "            }\n",
    "    param_rf.update(study_rf.best_trial.params) # select opt params in the model selection chapter\n",
    "\n",
    "    rf = RandomForestRegressor(**param_rf)\n",
    "    # train the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# print(\"running rf model\")\n",
    "# rf_model()\n",
    "\n",
    "\n",
    "## extra trees\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "def et_model():\n",
    "    global y_pred_et\n",
    "\n",
    "    param_et = {\n",
    "        \"n_estimators\": 167, \n",
    "        \"max_depth\": 44,\n",
    "        \"max_features\": 25,\n",
    "        # \"min_samples_leaf\": 1, \n",
    "        # \"min_samples_split\": 25,\n",
    "        \"n_jobs\": -1, \n",
    "        \"random_state\": 123\n",
    "        }\n",
    "    param_et.update(study_et.best_trial.params)\n",
    "\n",
    "\n",
    "    et = ExtraTreesRegressor(**param_et)\n",
    "    # train the model\n",
    "    et.fit(X_train, y_train) # execute train test split cell first\n",
    "    y_pred_et = et.predict(X_test)\n",
    "    \n",
    "# print(\"running et model\")\n",
    "# et_model()\n",
    "# y_pred_et\n",
    "\n",
    "\n",
    "## xgboost\n",
    "import xgboost\n",
    "\n",
    "def xgb_model():\n",
    "    global y_pred_xgb\n",
    "    param_xgb = {\n",
    "                    \"n_estimators\": 3000,\n",
    "                    \"max_depth\": 4,\n",
    "                    \"learning_rate\": 0.02,\n",
    "                    \"booster\": 'gbtree',\n",
    "                    \"n_jobs\": -1,\n",
    "                    \"random_state\": 123,\n",
    "                    \"eval_metric\": [\"mae\"],\n",
    "                    \"enable_categorical\": True,\n",
    "                    \"tree_method\": \"hist\",\n",
    "                    \"early_stopping_rounds\": 100, # tries for X more iterations after the first minimum was detected\n",
    "                }\n",
    "    param_xgb.update(study_xgb.best_trial.params) # use best optuna parameters\n",
    "\n",
    "    xgb = xgboost.XGBRegressor(**param_xgb)\n",
    "\n",
    "    xgb.fit(X_train, y_train,\n",
    "            eval_set = [(X_test, y_test)], #Eval set only to check for overfitting etc. and necessary for early_stopping_rounds!\n",
    "            verbose = False, # how many iteration steps are displayed. True -> show all \n",
    "            )\n",
    "            \n",
    "    # make predictions for test data based on the best test model determined before\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# print(\"running xgb model\")\n",
    "# xgb_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup X and y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070.58740610081, 137412.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4800.500325662831, 14342.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1999, 98)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sample restrictions\n",
    "df = df_raw.copy()\n",
    "\n",
    "# drop revenues >90% percentile\n",
    "df[\"actual_revenue\"].mean(), df[\"actual_revenue\"].max()\n",
    "df = df[(df[\"actual_revenue\"] >= df[\"actual_revenue\"].quantile(0.9)) & (df[\"actual_revenue\"] <= df[\"actual_revenue\"].quantile(.990))] # 49360.0: highest msft\n",
    "df[\"actual_revenue\"].mean(), df[\"actual_revenue\"].max()\n",
    "\n",
    "# cv: restrict to 80% | keep 20% as holdout\n",
    "###############################\n",
    "# df = df.iloc[:(int(df.shape[0]*0.8)), ]\n",
    "###############################\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manager setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection see model selection - random forest\n",
    "boruta_feats_manager = ['revenue_guidance_average', 'revenue_guidance_error_previous_rel', 'revenue_prev', 'revenue_prev2', 'revenue_prev3', 'receivables', 'cash_eq', 'rd_many_zeros', 'restructuring_charges_many_zeros', 'total_equity', 'gross_profit', 'assets', 'price_40days_change', 'nwc', 'cogs', 'cash_from_oper', 'liabilities', 'marketcap', 'change_nwc', 'firm_id', 'free_cash_flow', 'ebitda', 'goodwill', 'ebit', 'operating_income', 'short_interest_180_change', 'revenue_prev3_change', 'net_income', 'change_in_inventories_many_zeros', 'sga', 'inventory_turnover_many_zeros', 'revenue_prev2_change', 'revenue_guidance_range', 'restricted_cash_many_zeros', 'depreciation_amortization', 'short_interest_180', 'quarter_fama_industry_cat', 'cash_from_finance', 'price_180days_change', 'short_interest_15', 'inventory_many_zeros', 'work_in_progress_inventory_many_zeros', 'price_60days_change', 'gain_on_sale_invest_many_zeros', 'nwc_assets', 'raw_materials_inventory_many_zeros', 'price_40days', 'cash_asset_ratio', 'total_debt', 'capex', 'cash_from_invest', 'price_15days', 'beta_russell_60days', 'book_value_share', 'short_interest_15_change', 'capex_assets_ratio', 'short_interest_60_change', 'price_180days', 'price_vola_3month', 'finished_goods_inventory_many_zeros', 'price_60days', 'price_15days_change', 'short_interest_60', 'asset_writedown_many_zeros', 'price_vola_6month', 'selling_marketing_many_zeros', 'real_gdp_growth', 'gain_on_sale_assets_many_zeros', 'total_dividends_many_zeros', 'quarter_previous_cat', 'goodwill_impairment_many_zeros', 'warranty_liabilities_many_zeros', 'warranty_liablities_many_zeros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue_guidance_average</th>\n",
       "      <th>revenue_guidance_error_adjusted</th>\n",
       "      <th>revenue_guidance_range</th>\n",
       "      <th>revenue_guidance_error_previous_rel</th>\n",
       "      <th>revenue_prev</th>\n",
       "      <th>revenue_prev2</th>\n",
       "      <th>revenue_prev3</th>\n",
       "      <th>receivables</th>\n",
       "      <th>cash_eq</th>\n",
       "      <th>rd_many_zeros</th>\n",
       "      <th>restructuring_charges_many_zeros</th>\n",
       "      <th>total_equity</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>assets</th>\n",
       "      <th>price_40days_change</th>\n",
       "      <th>nwc</th>\n",
       "      <th>cogs</th>\n",
       "      <th>cash_from_oper</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>change_nwc</th>\n",
       "      <th>firm_id</th>\n",
       "      <th>free_cash_flow</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>quarter_fama_industry_cat</th>\n",
       "      <th>quarter_previous_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7350.0</td>\n",
       "      <td>7242.930591</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>7741.0</td>\n",
       "      <td>6126.0</td>\n",
       "      <td>6577.0</td>\n",
       "      <td>5095.0</td>\n",
       "      <td>5256.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51548.0</td>\n",
       "      <td>6197.0</td>\n",
       "      <td>65387.0</td>\n",
       "      <td>0.590723</td>\n",
       "      <td>-1808.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>13839.0</td>\n",
       "      <td>356806.17236</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>1198</td>\n",
       "      <td>-573.875</td>\n",
       "      <td>3796.0</td>\n",
       "      <td>2002Q136</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6700.0</td>\n",
       "      <td>6602.399314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>6869.0</td>\n",
       "      <td>6181.0</td>\n",
       "      <td>7312.0</td>\n",
       "      <td>4202.0</td>\n",
       "      <td>6392.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>-1468.0</td>\n",
       "      <td>11041.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>30163.0</td>\n",
       "      <td>1.708176</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>4629.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>19122.0</td>\n",
       "      <td>32744.94884</td>\n",
       "      <td>-428.0</td>\n",
       "      <td>1230</td>\n",
       "      <td>446.250</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2002Q337</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6900.0</td>\n",
       "      <td>6799.485861</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>6504.0</td>\n",
       "      <td>6319.0</td>\n",
       "      <td>6781.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>6678.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35307.0</td>\n",
       "      <td>3173.0</td>\n",
       "      <td>43636.0</td>\n",
       "      <td>1.186851</td>\n",
       "      <td>839.0</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>8329.0</td>\n",
       "      <td>97442.30000</td>\n",
       "      <td>-390.0</td>\n",
       "      <td>957</td>\n",
       "      <td>1278.000</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2002Q437</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023.2</td>\n",
       "      <td>1993.727506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11092.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>14899.0</td>\n",
       "      <td>0.716029</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>3807.0</td>\n",
       "      <td>25606.29401</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1796</td>\n",
       "      <td>257.375</td>\n",
       "      <td>529.0</td>\n",
       "      <td>2002Q437</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6700.0</td>\n",
       "      <td>6456.703911</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-0.036313</td>\n",
       "      <td>7160.0</td>\n",
       "      <td>6504.0</td>\n",
       "      <td>6319.0</td>\n",
       "      <td>2574.0</td>\n",
       "      <td>7404.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>-106.0</td>\n",
       "      <td>35468.0</td>\n",
       "      <td>3957.0</td>\n",
       "      <td>44224.0</td>\n",
       "      <td>0.715291</td>\n",
       "      <td>179.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>3521.0</td>\n",
       "      <td>8756.0</td>\n",
       "      <td>108650.00000</td>\n",
       "      <td>-660.0</td>\n",
       "      <td>957</td>\n",
       "      <td>1888.875</td>\n",
       "      <td>3078.0</td>\n",
       "      <td>2003Q137</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   revenue_guidance_average  revenue_guidance_error_adjusted  \\\n",
       "0                    7350.0                      7242.930591   \n",
       "1                    6700.0                      6602.399314   \n",
       "2                    6900.0                      6799.485861   \n",
       "3                    2023.2                      1993.727506   \n",
       "4                    6700.0                      6456.703911   \n",
       "\n",
       "   revenue_guidance_range  revenue_guidance_error_previous_rel  revenue_prev  \\\n",
       "0                   100.0                            -0.014567        7741.0   \n",
       "1                     0.0                            -0.014567        6869.0   \n",
       "2                   200.0                            -0.014567        6504.0   \n",
       "3                     0.0                            -0.014567        2248.0   \n",
       "4                   200.0                            -0.036313        7160.0   \n",
       "\n",
       "   revenue_prev2  revenue_prev3  receivables  cash_eq  rd_many_zeros  \\\n",
       "0         6126.0         6577.0       5095.0   5256.0         1044.0   \n",
       "1         6181.0         7312.0       4202.0   6392.0          925.0   \n",
       "2         6319.0         6781.0       3089.0   6678.0         1006.0   \n",
       "3         2162.0         1827.0       1503.0    964.0          415.0   \n",
       "4         6504.0         6319.0       2574.0   7404.0         1022.0   \n",
       "\n",
       "   restructuring_charges_many_zeros  total_equity  gross_profit   assets  \\\n",
       "0                               0.0       51548.0        6197.0  65387.0   \n",
       "1                           -1468.0       11041.0        2240.0  30163.0   \n",
       "2                               0.0       35307.0        3173.0  43636.0   \n",
       "3                               0.0       11092.0         835.0  14899.0   \n",
       "4                            -106.0       35468.0        3957.0  44224.0   \n",
       "\n",
       "   price_40days_change     nwc    cogs  cash_from_oper  liabilities  \\\n",
       "0             0.590723 -1808.0  1544.0          3565.0      13839.0   \n",
       "1             1.708176  1828.0  4629.0           527.0      19122.0   \n",
       "2             1.186851   839.0  3331.0          2391.0       8329.0   \n",
       "3             0.716029  1575.0  1413.0           565.0       3807.0   \n",
       "4             0.715291   179.0  3203.0          3521.0       8756.0   \n",
       "\n",
       "      marketcap  change_nwc  firm_id  free_cash_flow  ebitda  \\\n",
       "0  356806.17236      2885.0     1198        -573.875  3796.0   \n",
       "1   32744.94884      -428.0     1230         446.250    98.0   \n",
       "2   97442.30000      -390.0      957        1278.000  2194.0   \n",
       "3   25606.29401       -47.0     1796         257.375   529.0   \n",
       "4  108650.00000      -660.0      957        1888.875  3078.0   \n",
       "\n",
       "  quarter_fama_industry_cat quarter_previous_cat  \n",
       "0                  2002Q136                    4  \n",
       "1                  2002Q337                    2  \n",
       "2                  2002Q437                    3  \n",
       "3                  2002Q437                    3  \n",
       "4                  2003Q137                    4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1999, 26)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 26 | categorical_features: ['firm_id'] | categoricals_targetencode ['quarter_fama_industry_cat', 'quarter_previous_cat'] | forecast_feature: ['revenue_guidance_average', 'revenue_guidance_error_adjusted', 'revenue_guidance_range', 'revenue_guidance_error_previous_rel']\n"
     ]
    }
   ],
   "source": [
    "y = df[\"actual_revenue\"] # dependent variable\n",
    "\n",
    "forecast_feature = [\"revenue_guidance_average\", \"revenue_guidance_error_adjusted\", \"revenue_guidance_range\", \"revenue_guidance_error_previous_rel\"]\n",
    "\n",
    "# X_all = df.drop(columns=[\"actual_revenue\"] + df.filter(regex=\"guidance|analyst\").columns.tolist()).iloc[:, df.columns.get_loc(\"firm_id\"):]\n",
    "# floats = X_all.select_dtypes(include=[float]).columns.to_list()\n",
    "floats = boruta_feats_manager[:22]\n",
    "\n",
    "# print(df.select_dtypes(include=['category']).columns.to_list())\n",
    "categoricals_targetencode = ['quarter_fama_industry_cat', \"quarter_previous_cat\"]\n",
    "categoricals = [\"firm_id\"]\n",
    "\n",
    "features = forecast_feature + floats + categoricals_targetencode + categoricals\n",
    "X = df[pd.unique(features).tolist()].copy() # drop duplicate features\n",
    "\n",
    "# one_hot_encode() # irrelevant for lgbm\n",
    "\n",
    "X.head()\n",
    "X.shape\n",
    "print(f\"total features: {X.shape[1]} | categorical_features: {categoricals} | categoricals_targetencode {categoricals_targetencode} | forecast_feature: {forecast_feature}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boruta feature optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute random forest - boruta feature selection first\n",
    "boruta_feats_list, mae_list = [], []\n",
    "for i in range(10, len(boruta_feats_manager)):\n",
    "    print(f\"{i} of {len(boruta_feats_manager)}\")\n",
    "    y = df[\"actual_revenue\"] # dependent variable\n",
    "\n",
    "    forecast_feature = [\"revenue_guidance_average\", \"revenue_guidance_range\", \"revenue_guidance_error_previous_rel\"]\n",
    "    floats = boruta_feats_manager[:i]\n",
    "    categoricals_targetencode = ['quarter_fama_industry_cat', \"quarter_previous_cat\"]\n",
    "    categoricals = [\"firm_id\"]\n",
    "\n",
    "    features = forecast_feature + floats + categoricals_targetencode + categoricals\n",
    "    X = df[pd.unique(features).tolist()].copy() # drop duplicate features\n",
    "    X[\"revenue_guidance_error_adjusted\"] = (X['revenue_guidance_average'] * (1-np.abs(X['revenue_guidance_error_previous_rel'])))\n",
    "\n",
    "    ## automatic split\n",
    "    indices = range(X.shape[0])\n",
    "    X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size=0.2, shuffle=False)\n",
    "    ## manual indices\n",
    "    # train_start, train_end = 0, 5105+1\n",
    "    # test_start, test_end = train_end, 7658+1\n",
    "    # X_train, X_test, y_train, y_test, indices_train, indices_test  = X.iloc[:train_end, ], X.iloc[test_start:test_end, ], y.iloc[:train_end, ], y.iloc[test_start:test_end, ], np.array([i for i in range(train_end)]), np.array([i for i in range(test_start, test_end)])\n",
    "    ## target encoding\n",
    "    target_encoding(cat_columns=categoricals_targetencode, shrinking_factor=0)\n",
    "\n",
    "    lightgbm_model(param, num_boost_round=3000, features=X.columns.to_list(), log=-1)\n",
    "\n",
    "    y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    boruta_feats_list.append(i)\n",
    "    mae_list.append(mae) \n",
    "\n",
    "df_bf = pd.DataFrame({\"boruta_feats_list\": boruta_feats_list, \"mae_list\": mae_list})\n",
    "df_bf = df_bf.sort_values(by=\"mae_list\", ascending=True, ignore_index=True)\n",
    "df_bf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_count</th>\n",
       "      <th>sum</th>\n",
       "      <th>folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.474</td>\n",
       "      <td>[0.1, 0.124, 0.1, 0.1, 0.05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>0.486</td>\n",
       "      <td>[0.1, 0.135, 0.05, 0.1, 0.101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23</td>\n",
       "      <td>0.489</td>\n",
       "      <td>[0.1, 0.136, 0.05, 0.103, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.491</td>\n",
       "      <td>[0.1, 0.141, 0.1, 0.1, 0.05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>0.504</td>\n",
       "      <td>[0.1, 0.154, 0.05, 0.1, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>70</td>\n",
       "      <td>0.934</td>\n",
       "      <td>[0.1, 0.129, 0.1, 0.445, 0.16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>59</td>\n",
       "      <td>0.952</td>\n",
       "      <td>[0.106, 0.125, 0.1, 0.343, 0.278]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>63</td>\n",
       "      <td>0.979</td>\n",
       "      <td>[0.115, 0.129, 0.1, 0.326, 0.309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>72</td>\n",
       "      <td>1.009</td>\n",
       "      <td>[0.1, 0.127, 0.102, 0.426, 0.254]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>66</td>\n",
       "      <td>1.065</td>\n",
       "      <td>[0.105, 0.139, 0.1, 0.406, 0.315]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_count    sum                              folds\n",
       "1              11  0.474       [0.1, 0.124, 0.1, 0.1, 0.05]\n",
       "12             22  0.486     [0.1, 0.135, 0.05, 0.1, 0.101]\n",
       "13             23  0.489     [0.1, 0.136, 0.05, 0.103, 0.1]\n",
       "0              10  0.491       [0.1, 0.141, 0.1, 0.1, 0.05]\n",
       "11             21  0.504       [0.1, 0.154, 0.05, 0.1, 0.1]\n",
       "..            ...    ...                                ...\n",
       "60             70  0.934     [0.1, 0.129, 0.1, 0.445, 0.16]\n",
       "49             59  0.952  [0.106, 0.125, 0.1, 0.343, 0.278]\n",
       "53             63  0.979  [0.115, 0.129, 0.1, 0.326, 0.309]\n",
       "62             72  1.009  [0.1, 0.127, 0.102, 0.426, 0.254]\n",
       "56             66  1.065  [0.105, 0.139, 0.1, 0.406, 0.315]\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_count_folds = []\n",
    "feature_count_mean = []\n",
    "feature_count_list = []\n",
    "\n",
    "df = df_raw.copy()\n",
    "df = df[(df[\"actual_revenue\"] < df[\"actual_revenue\"].quantile(0.90))] # see geertsema paper\n",
    "df = df.iloc[:(int(df.shape[0]*0.8)), ]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "for feature_count in range(10, len(boruta_feats_manager)):\n",
    "# for feature_count in np.arange(0.89, 0.91, 0.001):\n",
    "    print(feature_count)\n",
    "    feature_count_list.append(feature_count)\n",
    "\n",
    "\n",
    "    y = df[\"actual_revenue\"] # dependent variable\n",
    "    forecast_feature = [\"revenue_guidance_average\", \"revenue_guidance_error_adjusted\", \"revenue_guidance_range\", \"revenue_guidance_error_previous_rel\"]\n",
    "    floats = boruta_feats_manager[:feature_count]\n",
    "    categoricals_targetencode = ['quarter_fama_industry_cat', \"quarter_previous_cat\"]\n",
    "    categoricals = [\"firm_id\"]\n",
    "    features = forecast_feature + floats + categoricals_targetencode + categoricals\n",
    "    X = df[pd.unique(features).tolist()].copy() # drop duplicate features\n",
    "    \n",
    "    # create empty list\n",
    "    p_results = []\n",
    "\n",
    "    # time series splits\n",
    "    tss = TimeSeriesSplit(n_splits=5)\n",
    "    for fold, (indices_train, indices_test) in enumerate(tss.split(X)):\n",
    "        # if fold in [2,3,4]:\n",
    "        #     continue\n",
    "        X_train, X_test = X.iloc[indices_train], X.iloc[indices_test]\n",
    "        y_train, y_test = y.iloc[indices_train], y.iloc[indices_test]\n",
    "\n",
    "        # target encoding\n",
    "        target_encoding(cat_columns=categoricals_targetencode, shrinking_factor=0)\n",
    "        # manager / analyst error\n",
    "        manager_analyst_accuracy(actual_var=\"actual_revenue\", manager_var=\"revenue_guidance_average\", analyst_var=\"analyst_mean_guidance_date\")\n",
    "\n",
    "        # model \n",
    "        lightgbm_model(param, num_boost_round=3000, features=X.columns.to_list(), log=False) # param_opt for most recent optuna params\n",
    "\n",
    "        # results\n",
    "        p = stats.ttest_ind(a=np.array(abs(y_pred-y_test)), b=np.array(abs(X_manager_test-y_test)), equal_var=False)[1]\n",
    "        if p < 0.01:\n",
    "            p = 0.01\n",
    "        elif p <= 0.05:\n",
    "            p = 0.05\n",
    "        elif p <= 0.1:\n",
    "            p = 0.1\n",
    "        p = round(p, 3)\n",
    "        p_results.append(p)\n",
    "\n",
    "    # objective which should be minimized\n",
    "    feature_count_mean.append(sum(p_results))\n",
    "    feature_count_folds.append(p_results)\n",
    "\n",
    "df_feature_count = pd.DataFrame({\"feature_count\": feature_count_list, \"sum\": feature_count_mean, \"folds\": feature_count_folds})\n",
    "df_feature_count = df_feature_count.sort_values(by=[\"sum\"], ascending=True)\n",
    "df_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete: (1999, 26) train: (1599, 26) test: (400, 26)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[502]\tvalid_0's l1: 203.855\n",
      "Evaluated only: l1\n",
      "\n",
      "**********\n",
      "model test MAE (RMSE): 203.8547 (364.5648)\n",
      "manager test MAE (RMSE): 218.1555 (367.549)\n",
      "analyst test MAE (RMSE): 283.9965 (432.3639)\n",
      "\n",
      "**********\n",
      "model vs manager: edge -0.066 | t-stat -0.675 p-value 0.5\n",
      "model vs analyst: edge -0.282 | t-stat -3.601 p-value 0.0\n",
      "\n",
      "************************************\n"
     ]
    }
   ],
   "source": [
    "## automatic split\n",
    "indices = range(X.shape[0]) # list containing all indices of the df\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size=0.2, shuffle=False)\n",
    "\n",
    "## manual indices\n",
    "# train_start, train_end = 0, 2667+1\n",
    "# test_start, test_end = train_end, 5333+1\n",
    "# X_train, X_test, y_train, y_test, indices_train, indices_test  = X.iloc[:train_end, ], X.iloc[test_start:test_end, ], y.iloc[:train_end, ], y.iloc[test_start:test_end, ], np.array([i for i in range(train_end)]), np.array([i for i in range(test_start, test_end)])\n",
    "\n",
    "print(f\"complete: {X.shape} train: {X_train.shape} test: {X_test.shape}\")\n",
    "## target encoding\n",
    "target_encoding(cat_columns=categoricals_targetencode, shrinking_factor=0.0)\n",
    "\n",
    "## standard scaling of features (irrelevant for most models)\n",
    "# standard_scaling()\n",
    "\n",
    "## manager / analyst error\n",
    "manager_analyst_accuracy(actual_var=\"actual_revenue\", manager_var=\"revenue_guidance_average\", analyst_var=\"analyst_mean_guidance_date\")\n",
    "\n",
    "## model\n",
    "lightgbm_model(param, num_boost_round=3000, features=X.columns.to_list())\n",
    "model_performance(y_pred=y_pred, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>split</th>\n",
       "      <th>relative gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revenue_guidance_error_previous_rel</td>\n",
       "      <td>1118</td>\n",
       "      <td>3.152770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>revenue_guidance_average</td>\n",
       "      <td>987</td>\n",
       "      <td>78.384655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>revenue_guidance_error_adjusted</td>\n",
       "      <td>750</td>\n",
       "      <td>11.662495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>revenue_prev</td>\n",
       "      <td>424</td>\n",
       "      <td>1.525003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>marketcap</td>\n",
       "      <td>405</td>\n",
       "      <td>0.650186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>price_40days_change</td>\n",
       "      <td>367</td>\n",
       "      <td>0.331233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cogs</td>\n",
       "      <td>293</td>\n",
       "      <td>0.317245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>firm_id</td>\n",
       "      <td>281</td>\n",
       "      <td>0.261733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>revenue_prev2</td>\n",
       "      <td>262</td>\n",
       "      <td>0.336249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cash_eq</td>\n",
       "      <td>259</td>\n",
       "      <td>0.289057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature  split  relative gain\n",
       "3   revenue_guidance_error_previous_rel   1118       3.152770\n",
       "0              revenue_guidance_average    987      78.384655\n",
       "1       revenue_guidance_error_adjusted    750      11.662495\n",
       "4                          revenue_prev    424       1.525003\n",
       "19                            marketcap    405       0.650186\n",
       "14                  price_40days_change    367       0.331233\n",
       "16                                 cogs    293       0.317245\n",
       "21                              firm_id    281       0.261733\n",
       "5                         revenue_prev2    262       0.336249\n",
       "8                               cash_eq    259       0.289057"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "used_features = bst.feature_name()\n",
    "# print(used_features)\n",
    "\n",
    "max_feature_to_plot = 10\n",
    "\n",
    "gain = bst.feature_importance('gain')\n",
    "featureimp = pd.DataFrame({'feature':bst.feature_name(), \n",
    "                   'split':bst.feature_importance('split'), \n",
    "                   'relative gain':100 * gain / gain.sum()}).sort_values('split', ascending=False)\n",
    "featureimp[:max_feature_to_plot]\n",
    "# print(featureimp[\"feature\"].to_list()[20:])\n",
    "\n",
    "lightgbm.plot_importance(bst, importance_type=\"split\", max_num_features=max_feature_to_plot, figsize=(8,4))\n",
    "plt.show()\n",
    "\n",
    "lightgbm.plot_importance(bst, importance_type=\"gain\", max_num_features=max_feature_to_plot, figsize=(8,4))\n",
    "plt.show()\n",
    "\n",
    "# If \"split\", result contains numbers of times the feature is used in a model (number of times a feature is used to split a node in all used iterations).\n",
    "# If \"gain\", result contains total gains of splits which use the feature. In decision tree regression models, feature importance gain is a measure of how much a specific feature contributes to reducing the variance of the target variable when it is used to split the tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap_values = shap.TreeExplainer(bst).shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test)#### firm prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save best lgbm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mape and rmse of full model (without any forecast features) is better than analysts after removing revenues > 90%\n",
    "bst.save_model(Path.joinpath(Path.cwd().parent / '1 Data' / '2 Models', \"112922_winAll2_actualrev90percentile_rmse-l-vs-analyst.csv\"))\n",
    "# lgbm with all vars + rev guidance is best after removing revenues > 90%\n",
    "bst.save_model(Path.joinpath(Path.cwd().parent / '1 Data' / '2 Models', \"112922_winAll2_actualrev90percentile_withRevGuid_allvars.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mae vs rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.DataFrame({\"actual\": y_test, \"lgbm\": y_pred, \"manager\": X_manager_test, \"analyst\": X_analyst_test, \"lgbm_error\": y_test-y_pred, \"manager_error\": y_test-X_manager_test, \"analyst_error\": y_test-X_analyst_test})\n",
    "\n",
    "round(mean_absolute_error(df_c[\"actual\"], df_c[\"lgbm\"]), 4), round(mean_absolute_error(df_c[\"actual\"], df_c[\"manager\"]), 4), round(mean_absolute_error(df_c[\"actual\"], df_c[\"analyst\"]), 4)\n",
    "round(mean_squared_error(df_c[\"actual\"], df_c[\"lgbm\"], squared=False), 4), round(mean_squared_error(df_c[\"actual\"], df_c[\"manager\"], squared=False), 4), round(mean_squared_error(df_c[\"actual\"], df_c[\"analyst\"], squared=False), 4)\n",
    "\n",
    "df_c = df_c[(df_c[\"lgbm_error\"] > df_c[\"lgbm_error\"].quantile(.95))] # see geertsema paper\n",
    "df_c\n",
    "\n",
    "round(mean_absolute_error(df_c[\"actual\"], df_c[\"lgbm\"]), 4), round(mean_absolute_error(df_c[\"actual\"], df_c[\"manager\"]), 4), round(mean_absolute_error(df_c[\"actual\"], df_c[\"analyst\"]), 4)\n",
    "round(mean_squared_error(df_c[\"actual\"], df_c[\"lgbm\"], squared=False), 4), round(mean_squared_error(df_c[\"actual\"], df_c[\"manager\"], squared=False), 4), round(mean_squared_error(df_c[\"actual\"], df_c[\"analyst\"], squared=False), 4)\n",
    "\n",
    "outlier = df_c.index.tolist()\n",
    "# print(outlier)\n",
    "\n",
    "# plot distriubtion of the model error\n",
    "# histo = plt.hist(y_test - y_pred, 100, density=True, facecolor='b', histtype=\"bar\")\n",
    "# plt.xlim(-200,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### firm prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[692]\tvalid_0's l1: 257.505\n",
      "Evaluated only: l1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>quarter_guided</th>\n",
       "      <th>actual_revenue</th>\n",
       "      <th>revenue_guidance_average</th>\n",
       "      <th>y_pred_lgbm</th>\n",
       "      <th>y_pred_avg</th>\n",
       "      <th>error_manager</th>\n",
       "      <th>error_lgbm</th>\n",
       "      <th>error_ensemble</th>\n",
       "      <th>delta_manager_lgbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1693</td>\n",
       "      <td>2020Q1</td>\n",
       "      <td>5854.0</td>\n",
       "      <td>5862.098</td>\n",
       "      <td>5879.129942</td>\n",
       "      <td>5858.665241</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>2.094238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962</td>\n",
       "      <td>2021Q3</td>\n",
       "      <td>6559.0</td>\n",
       "      <td>6478.270</td>\n",
       "      <td>6558.639814</td>\n",
       "      <td>6758.492554</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.029517</td>\n",
       "      <td>-0.995593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2021Q4</td>\n",
       "      <td>7059.0</td>\n",
       "      <td>6710.660</td>\n",
       "      <td>6544.720155</td>\n",
       "      <td>6775.920619</td>\n",
       "      <td>0.051908</td>\n",
       "      <td>0.078579</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.513806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2071</td>\n",
       "      <td>2022Q1</td>\n",
       "      <td>7189.0</td>\n",
       "      <td>6817.510</td>\n",
       "      <td>7051.834787</td>\n",
       "      <td>7121.040667</td>\n",
       "      <td>0.054491</td>\n",
       "      <td>0.019451</td>\n",
       "      <td>0.009543</td>\n",
       "      <td>-0.643039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2132</td>\n",
       "      <td>2022Q2</td>\n",
       "      <td>7275.0</td>\n",
       "      <td>7018.850</td>\n",
       "      <td>7352.033873</td>\n",
       "      <td>7376.959050</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.013821</td>\n",
       "      <td>-0.712892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index quarter_guided  actual_revenue  revenue_guidance_average  \\\n",
       "0   1693         2020Q1          5854.0                  5862.098   \n",
       "1   1962         2021Q3          6559.0                  6478.270   \n",
       "2   2023         2021Q4          7059.0                  6710.660   \n",
       "3   2071         2022Q1          7189.0                  6817.510   \n",
       "4   2132         2022Q2          7275.0                  7018.850   \n",
       "\n",
       "   y_pred_lgbm   y_pred_avg  error_manager  error_lgbm  error_ensemble  \\\n",
       "0  5879.129942  5858.665241       0.001381    0.004274        0.000796   \n",
       "1  6558.639814  6758.492554       0.012462    0.000055        0.029517   \n",
       "2  6544.720155  6775.920619       0.051908    0.078579        0.041777   \n",
       "3  7051.834787  7121.040667       0.054491    0.019451        0.009543   \n",
       "4  7352.033873  7376.959050       0.036495    0.010478        0.013821   \n",
       "\n",
       "   delta_manager_lgbm  \n",
       "0            2.094238  \n",
       "1           -0.995593  \n",
       "2            0.513806  \n",
       "3           -0.643039  \n",
       "4           -0.712892  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.05130410054892596"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sample restrictions\n",
    "df = df_raw.copy()\n",
    "\n",
    "# drop revenues >90% percentile\n",
    "df = df[\n",
    "    (df[\"actual_revenue\"] >= df[\"actual_revenue\"].quantile(.90)) & \n",
    "    (df[\"actual_revenue\"] <= 49360.0)\n",
    "    ] # 49360.0: highest msft\n",
    "    \n",
    "# df = df.iloc[:(int(df.shape[0]*0.8)), ]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "y = df[\"actual_revenue\"] # dependent variable\n",
    "forecast_feature = [\"revenue_guidance_average\", \"revenue_guidance_error_adjusted\", \"revenue_guidance_range\", \"revenue_guidance_error_previous_rel\"]\n",
    "floats = boruta_feats_manager[:21]\n",
    "categoricals_targetencode = ['quarter_fama_industry_cat', \"quarter_previous_cat\"]\n",
    "categoricals = [\"firm_id\"]\n",
    "\n",
    "features = forecast_feature + floats + categoricals_targetencode + categoricals\n",
    "X = df[pd.unique(features).tolist()].copy() # drop duplicate features\n",
    "\n",
    "## automatic split\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size=0.2, shuffle=False)\n",
    "## target encoding\n",
    "target_encoding(cat_columns=categoricals_targetencode, shrinking_factor=0.0)\n",
    "## train model\n",
    "lightgbm_model(param, num_boost_round=3000, features=X.columns.to_list())\n",
    "\n",
    "\n",
    "# US6541061031\n",
    "# msft US5949181045\n",
    "# overwrite test with specific firm\n",
    "df_firm = df[df[\"isin\"] == \"US92826C8394\"]\n",
    "df_firm_year = df_firm[df_firm[\"quarter_guided\"].dt.year >= 2020]\n",
    "\n",
    "# overwrite X and y test\n",
    "y_test = df_firm_year[\"actual_revenue\"] # dependent variable\n",
    "\n",
    "forecast_feature = [\"revenue_guidance_average\", \"revenue_guidance_error_adjusted\", \"revenue_guidance_range\", \"revenue_guidance_error_previous_rel\"]\n",
    "floats = boruta_feats_manager[:21]\n",
    "categoricals_targetencode = ['quarter_fama_industry_cat', \"quarter_previous_cat\"]\n",
    "categoricals = [\"firm_id\"]\n",
    "\n",
    "features = forecast_feature + floats + categoricals_targetencode + categoricals\n",
    "X_test = df_firm_year[pd.unique(features).tolist()].copy() # drop duplicate features\n",
    "\n",
    "target_encoding(cat_columns=categoricals_targetencode, shrinking_factor=0.0)\n",
    "\n",
    "# run model\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "et_model()\n",
    "xgb_model()\n",
    "rf_model()\n",
    "\n",
    "ensemble_weights = {'weight_model1': 0.63, 'weight_model2': 0.22, 'weight_model3': 0.15, 'weight_model4': 0.0}\n",
    "y_pred_avg_firm = ensemble_weights[\"weight_model1\"]*y_pred + ensemble_weights[\"weight_model2\"]*y_pred_et + ensemble_weights[\"weight_model3\"]*y_pred_xgb + ensemble_weights[\"weight_model4\"]*y_pred_rf\n",
    "\n",
    "# results\n",
    "df_single = df_firm_year[[\"quarter_guided\", \"actual_revenue\", \"revenue_guidance_average\"]].reset_index()\n",
    "df_single = pd.concat([df_single, pd.DataFrame({\"y_pred_lgbm\": y_pred, \"y_pred_avg\": y_pred_avg_firm})], axis=1)\n",
    "df_single[\"error_manager\"] = np.abs(df_single[\"actual_revenue\"] / df_single[\"revenue_guidance_average\"] - 1)\n",
    "df_single[\"error_lgbm\"] = np.abs(df_single[\"actual_revenue\"] / df_single[\"y_pred_lgbm\"] - 1)\n",
    "df_single[\"error_ensemble\"] = np.abs(df_single[\"actual_revenue\"] / df_single[\"y_pred_avg\"] - 1)\n",
    "df_single[\"delta_manager_lgbm\"] = df_single[\"error_lgbm\"] / df_single[\"error_manager\"] - 1\n",
    "df_single\n",
    "\n",
    "df_single[\"delta_manager_lgbm\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-15 20:34:24,604]\u001b[0m A new study created in memory with name: no-name-2c081971-f555-4e8b-9b3f-9e5b9a8e2b29\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:25,012]\u001b[0m Trial 0 finished with value: 239.85850079688797 and parameters: {'num_leaves': 96, 'learning_rate': 0.05, 'max_depth': 6, 'min_data_in_leaf': 15}. Best is trial 0 with value: 239.85850079688797.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:25,215]\u001b[0m Trial 1 finished with value: 261.8947807267024 and parameters: {'num_leaves': 34, 'learning_rate': 0.04, 'max_depth': 5, 'min_data_in_leaf': 24}. Best is trial 0 with value: 239.85850079688797.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:25,480]\u001b[0m Trial 2 finished with value: 243.1035473991837 and parameters: {'num_leaves': 34, 'learning_rate': 0.06, 'max_depth': 7, 'min_data_in_leaf': 16}. Best is trial 0 with value: 239.85850079688797.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:25,579]\u001b[0m Trial 3 finished with value: 247.096042413621 and parameters: {'num_leaves': 63, 'learning_rate': 0.09000000000000001, 'max_depth': 3, 'min_data_in_leaf': 30}. Best is trial 0 with value: 239.85850079688797.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:25,917]\u001b[0m Trial 4 finished with value: 261.0163809430032 and parameters: {'num_leaves': 57, 'learning_rate': 0.07, 'max_depth': 8, 'min_data_in_leaf': 24}. Best is trial 0 with value: 239.85850079688797.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:26,090]\u001b[0m Trial 5 finished with value: 258.5215789597718 and parameters: {'num_leaves': 20, 'learning_rate': 0.09000000000000001, 'max_depth': 5, 'min_data_in_leaf': 8}. Best is trial 0 with value: 239.85850079688797.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:26,588]\u001b[0m Trial 6 finished with value: 252.72326063940645 and parameters: {'num_leaves': 76, 'learning_rate': 0.05, 'max_depth': 4, 'min_data_in_leaf': 20}. Best is trial 0 with value: 239.85850079688797.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:26,757]\u001b[0m Trial 7 finished with value: 245.0663610518526 and parameters: {'num_leaves': 40, 'learning_rate': 0.07, 'max_depth': 5, 'min_data_in_leaf': 28}. Best is trial 0 with value: 239.85850079688797.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:26,847]\u001b[0m Trial 8 finished with value: 234.22682259431386 and parameters: {'num_leaves': 55, 'learning_rate': 0.05, 'max_depth': 3, 'min_data_in_leaf': 25}. Best is trial 8 with value: 234.22682259431386.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:27,242]\u001b[0m Trial 9 finished with value: 261.8277153810304 and parameters: {'num_leaves': 28, 'learning_rate': 0.09000000000000001, 'max_depth': 7, 'min_data_in_leaf': 11}. Best is trial 8 with value: 234.22682259431386.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:27,596]\u001b[0m Trial 10 finished with value: 219.34984215196187 and parameters: {'num_leaves': 77, 'learning_rate': 0.02, 'max_depth': 3, 'min_data_in_leaf': 39}. Best is trial 10 with value: 219.34984215196187.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:27,992]\u001b[0m Trial 11 finished with value: 231.01429232943295 and parameters: {'num_leaves': 79, 'learning_rate': 0.02, 'max_depth': 3, 'min_data_in_leaf': 38}. Best is trial 10 with value: 219.34984215196187.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:28,235]\u001b[0m Trial 12 finished with value: 212.55570107636154 and parameters: {'num_leaves': 87, 'learning_rate': 0.02, 'max_depth': 3, 'min_data_in_leaf': 40}. Best is trial 12 with value: 212.55570107636154.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:28,638]\u001b[0m Trial 13 finished with value: 255.68672300527479 and parameters: {'num_leaves': 97, 'learning_rate': 0.02, 'max_depth': 4, 'min_data_in_leaf': 40}. Best is trial 12 with value: 212.55570107636154.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:28,744]\u001b[0m Trial 14 finished with value: 199.1813540737364 and parameters: {'num_leaves': 6, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 34}. Best is trial 14 with value: 199.1813540737364.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:28,893]\u001b[0m Trial 15 finished with value: 196.37995075801047 and parameters: {'num_leaves': 3, 'learning_rate': 0.03, 'max_depth': 8, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:29,015]\u001b[0m Trial 16 finished with value: 202.18634313263698 and parameters: {'num_leaves': 4, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:29,125]\u001b[0m Trial 17 finished with value: 200.55603040690028 and parameters: {'num_leaves': 8, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 34}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:29,358]\u001b[0m Trial 18 finished with value: 208.11544952521382 and parameters: {'num_leaves': 15, 'learning_rate': 0.03, 'max_depth': 8, 'min_data_in_leaf': 34}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:29,511]\u001b[0m Trial 19 finished with value: 215.86747637333872 and parameters: {'num_leaves': 18, 'learning_rate': 0.04, 'max_depth': 8, 'min_data_in_leaf': 30}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:29,651]\u001b[0m Trial 20 finished with value: 203.61726787986714 and parameters: {'num_leaves': 2, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 36}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:29,759]\u001b[0m Trial 21 finished with value: 203.10107936838796 and parameters: {'num_leaves': 9, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 32}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:29,962]\u001b[0m Trial 22 finished with value: 210.50000806019432 and parameters: {'num_leaves': 12, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 35}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:30,141]\u001b[0m Trial 23 finished with value: 216.54962999427906 and parameters: {'num_leaves': 23, 'learning_rate': 0.04, 'max_depth': 8, 'min_data_in_leaf': 27}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:30,216]\u001b[0m Trial 24 finished with value: 202.36074043405335 and parameters: {'num_leaves': 2, 'learning_rate': 0.06, 'max_depth': 7, 'min_data_in_leaf': 21}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:30,655]\u001b[0m Trial 25 finished with value: 250.2964206381081 and parameters: {'num_leaves': 47, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 31}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:30,755]\u001b[0m Trial 26 finished with value: 204.7191221726276 and parameters: {'num_leaves': 8, 'learning_rate': 0.05, 'max_depth': 8, 'min_data_in_leaf': 36}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:31,208]\u001b[0m Trial 27 finished with value: 232.5248166642049 and parameters: {'num_leaves': 26, 'learning_rate': 0.04, 'max_depth': 7, 'min_data_in_leaf': 27}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:31,317]\u001b[0m Trial 28 finished with value: 208.87921108906758 and parameters: {'num_leaves': 11, 'learning_rate': 0.1, 'max_depth': 9, 'min_data_in_leaf': 29}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:31,637]\u001b[0m Trial 29 finished with value: 241.98323278268697 and parameters: {'num_leaves': 30, 'learning_rate': 0.05, 'max_depth': 6, 'min_data_in_leaf': 18}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:31,743]\u001b[0m Trial 30 finished with value: 213.64600213845296 and parameters: {'num_leaves': 17, 'learning_rate': 0.07, 'max_depth': 8, 'min_data_in_leaf': 37}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:31,896]\u001b[0m Trial 31 finished with value: 196.37995075801047 and parameters: {'num_leaves': 3, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:31,998]\u001b[0m Trial 32 finished with value: 199.6088225166619 and parameters: {'num_leaves': 6, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:32,120]\u001b[0m Trial 33 finished with value: 202.44169098641373 and parameters: {'num_leaves': 2, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 32}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:32,832]\u001b[0m Trial 34 finished with value: 252.79159311747273 and parameters: {'num_leaves': 39, 'learning_rate': 0.02, 'max_depth': 8, 'min_data_in_leaf': 26}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:33,057]\u001b[0m Trial 35 finished with value: 205.45317731902776 and parameters: {'num_leaves': 13, 'learning_rate': 0.03, 'max_depth': 7, 'min_data_in_leaf': 30}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:33,318]\u001b[0m Trial 36 finished with value: 213.2372988805394 and parameters: {'num_leaves': 21, 'learning_rate': 0.04, 'max_depth': 8, 'min_data_in_leaf': 23}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:33,426]\u001b[0m Trial 37 finished with value: 202.47328386106648 and parameters: {'num_leaves': 8, 'learning_rate': 0.06, 'max_depth': 9, 'min_data_in_leaf': 37}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:33,952]\u001b[0m Trial 38 finished with value: 240.27351679045466 and parameters: {'num_leaves': 32, 'learning_rate': 0.02, 'max_depth': 9, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:34,390]\u001b[0m Trial 39 finished with value: 233.85767497327777 and parameters: {'num_leaves': 24, 'learning_rate': 0.08, 'max_depth': 7, 'min_data_in_leaf': 12}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:34,612]\u001b[0m Trial 40 finished with value: 231.49766812222333 and parameters: {'num_leaves': 67, 'learning_rate': 0.05, 'max_depth': 8, 'min_data_in_leaf': 29}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:34,744]\u001b[0m Trial 41 finished with value: 204.1926945319636 and parameters: {'num_leaves': 7, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 34}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:34,944]\u001b[0m Trial 42 finished with value: 205.7016215741257 and parameters: {'num_leaves': 13, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 34}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:35,053]\u001b[0m Trial 43 finished with value: 204.72629371359 and parameters: {'num_leaves': 6, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 38}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:35,205]\u001b[0m Trial 44 finished with value: 213.10867773202764 and parameters: {'num_leaves': 17, 'learning_rate': 0.03, 'max_depth': 8, 'min_data_in_leaf': 31}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:35,350]\u001b[0m Trial 45 finished with value: 199.7399690051178 and parameters: {'num_leaves': 7, 'learning_rate': 0.02, 'max_depth': 9, 'min_data_in_leaf': 35}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:36,187]\u001b[0m Trial 46 finished with value: 252.8180016982994 and parameters: {'num_leaves': 37, 'learning_rate': 0.02, 'max_depth': 8, 'min_data_in_leaf': 36}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:36,743]\u001b[0m Trial 47 finished with value: 242.42387833911343 and parameters: {'num_leaves': 20, 'learning_rate': 0.02, 'max_depth': 5, 'min_data_in_leaf': 39}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:37,771]\u001b[0m Trial 48 finished with value: 235.50094464263108 and parameters: {'num_leaves': 44, 'learning_rate': 0.02, 'max_depth': 9, 'min_data_in_leaf': 6}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:37,949]\u001b[0m Trial 49 finished with value: 200.2646387377219 and parameters: {'num_leaves': 4, 'learning_rate': 0.03, 'max_depth': 4, 'min_data_in_leaf': 32}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:38,244]\u001b[0m Trial 50 finished with value: 208.28611033591594 and parameters: {'num_leaves': 14, 'learning_rate': 0.02, 'max_depth': 9, 'min_data_in_leaf': 24}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:38,400]\u001b[0m Trial 51 finished with value: 200.32923098926236 and parameters: {'num_leaves': 5, 'learning_rate': 0.03, 'max_depth': 4, 'min_data_in_leaf': 32}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:38,562]\u001b[0m Trial 52 finished with value: 201.84561881478797 and parameters: {'num_leaves': 2, 'learning_rate': 0.03, 'max_depth': 6, 'min_data_in_leaf': 35}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:38,708]\u001b[0m Trial 53 finished with value: 204.7973576823257 and parameters: {'num_leaves': 10, 'learning_rate': 0.03, 'max_depth': 4, 'min_data_in_leaf': 28}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:38,902]\u001b[0m Trial 54 finished with value: 209.13635151354814 and parameters: {'num_leaves': 6, 'learning_rate': 0.02, 'max_depth': 5, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:39,060]\u001b[0m Trial 55 finished with value: 211.74078538225476 and parameters: {'num_leaves': 16, 'learning_rate': 0.04, 'max_depth': 6, 'min_data_in_leaf': 38}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:39,261]\u001b[0m Trial 56 finished with value: 203.76717167445065 and parameters: {'num_leaves': 11, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 35}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:39,709]\u001b[0m Trial 57 finished with value: 246.11769339011676 and parameters: {'num_leaves': 63, 'learning_rate': 0.02, 'max_depth': 8, 'min_data_in_leaf': 31}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:39,826]\u001b[0m Trial 58 finished with value: 205.89827005360166 and parameters: {'num_leaves': 4, 'learning_rate': 0.03, 'max_depth': 7, 'min_data_in_leaf': 40}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:40,280]\u001b[0m Trial 59 finished with value: 250.9143459457726 and parameters: {'num_leaves': 93, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 29}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:40,509]\u001b[0m Trial 60 finished with value: 204.04575851429 and parameters: {'num_leaves': 10, 'learning_rate': 0.02, 'max_depth': 8, 'min_data_in_leaf': 32}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:40,645]\u001b[0m Trial 61 finished with value: 202.18634313263698 and parameters: {'num_leaves': 4, 'learning_rate': 0.03, 'max_depth': 4, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:40,794]\u001b[0m Trial 62 finished with value: 207.1541625193291 and parameters: {'num_leaves': 5, 'learning_rate': 0.03, 'max_depth': 3, 'min_data_in_leaf': 36}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:40,912]\u001b[0m Trial 63 finished with value: 205.52732043434804 and parameters: {'num_leaves': 8, 'learning_rate': 0.04, 'max_depth': 4, 'min_data_in_leaf': 31}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:41,041]\u001b[0m Trial 64 finished with value: 202.44169098641373 and parameters: {'num_leaves': 2, 'learning_rate': 0.03, 'max_depth': 4, 'min_data_in_leaf': 34}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:41,219]\u001b[0m Trial 65 finished with value: 210.2076179660375 and parameters: {'num_leaves': 14, 'learning_rate': 0.02, 'max_depth': 5, 'min_data_in_leaf': 30}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:41,430]\u001b[0m Trial 66 finished with value: 232.24771354393147 and parameters: {'num_leaves': 20, 'learning_rate': 0.03, 'max_depth': 3, 'min_data_in_leaf': 32}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:41,574]\u001b[0m Trial 67 finished with value: 205.92865582118685 and parameters: {'num_leaves': 5, 'learning_rate': 0.03, 'max_depth': 4, 'min_data_in_leaf': 37}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:41,726]\u001b[0m Trial 68 finished with value: 206.50926335152167 and parameters: {'num_leaves': 11, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 35}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:41,976]\u001b[0m Trial 69 finished with value: 223.2559448622456 and parameters: {'num_leaves': 26, 'learning_rate': 0.05, 'max_depth': 9, 'min_data_in_leaf': 27}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:42,327]\u001b[0m Trial 70 finished with value: 237.3002021835307 and parameters: {'num_leaves': 17, 'learning_rate': 0.02, 'max_depth': 3, 'min_data_in_leaf': 14}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:42,469]\u001b[0m Trial 71 finished with value: 203.45915542179654 and parameters: {'num_leaves': 8, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 34}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:42,566]\u001b[0m Trial 72 finished with value: 203.82666996482578 and parameters: {'num_leaves': 2, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 32}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:42,722]\u001b[0m Trial 73 finished with value: 198.06609126298503 and parameters: {'num_leaves': 7, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:42,834]\u001b[0m Trial 74 finished with value: 199.6088225166619 and parameters: {'num_leaves': 6, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:43,002]\u001b[0m Trial 75 finished with value: 207.06496742831135 and parameters: {'num_leaves': 12, 'learning_rate': 0.02, 'max_depth': 9, 'min_data_in_leaf': 36}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:43,616]\u001b[0m Trial 76 finished with value: 246.69285948567173 and parameters: {'num_leaves': 55, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:43,717]\u001b[0m Trial 77 finished with value: 203.03272379481504 and parameters: {'num_leaves': 8, 'learning_rate': 0.04, 'max_depth': 8, 'min_data_in_leaf': 30}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:43,862]\u001b[0m Trial 78 finished with value: 209.01981709039953 and parameters: {'num_leaves': 15, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 37}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:43,932]\u001b[0m Trial 79 finished with value: 205.2761623474062 and parameters: {'num_leaves': 6, 'learning_rate': 0.1, 'max_depth': 8, 'min_data_in_leaf': 28}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:44,127]\u001b[0m Trial 80 finished with value: 203.74660757428632 and parameters: {'num_leaves': 10, 'learning_rate': 0.02, 'max_depth': 9, 'min_data_in_leaf': 25}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:44,263]\u001b[0m Trial 81 finished with value: 202.18634313263698 and parameters: {'num_leaves': 4, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:44,390]\u001b[0m Trial 82 finished with value: 200.13744910824062 and parameters: {'num_leaves': 6, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 35}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:44,526]\u001b[0m Trial 83 finished with value: 210.16272851530178 and parameters: {'num_leaves': 13, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 35}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:44,699]\u001b[0m Trial 84 finished with value: 202.9314231626605 and parameters: {'num_leaves': 7, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 39}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:44,822]\u001b[0m Trial 85 finished with value: 204.1333275563464 and parameters: {'num_leaves': 2, 'learning_rate': 0.07, 'max_depth': 9, 'min_data_in_leaf': 34}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:45,024]\u001b[0m Trial 86 finished with value: 201.70596808224985 and parameters: {'num_leaves': 10, 'learning_rate': 0.03, 'max_depth': 8, 'min_data_in_leaf': 35}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:45,215]\u001b[0m Trial 87 finished with value: 201.37103415919285 and parameters: {'num_leaves': 4, 'learning_rate': 0.02, 'max_depth': 9, 'min_data_in_leaf': 31}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:45,406]\u001b[0m Trial 88 finished with value: 213.33261566936562 and parameters: {'num_leaves': 23, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 36}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:45,528]\u001b[0m Trial 89 finished with value: 227.09777093621543 and parameters: {'num_leaves': 18, 'learning_rate': 0.08, 'max_depth': 8, 'min_data_in_leaf': 33}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:45,620]\u001b[0m Trial 90 finished with value: 202.79490279276558 and parameters: {'num_leaves': 6, 'learning_rate': 0.05, 'max_depth': 8, 'min_data_in_leaf': 37}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:45,832]\u001b[0m Trial 91 finished with value: 204.8202846014341 and parameters: {'num_leaves': 8, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 32}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:45,958]\u001b[0m Trial 92 finished with value: 201.29076105491885 and parameters: {'num_leaves': 4, 'learning_rate': 0.03, 'max_depth': 6, 'min_data_in_leaf': 34}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:46,065]\u001b[0m Trial 93 finished with value: 206.6335974779335 and parameters: {'num_leaves': 12, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 29}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:46,230]\u001b[0m Trial 94 finished with value: 201.50782684575807 and parameters: {'num_leaves': 9, 'learning_rate': 0.03, 'max_depth': 5, 'min_data_in_leaf': 30}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:46,754]\u001b[0m Trial 95 finished with value: 240.93195035683016 and parameters: {'num_leaves': 82, 'learning_rate': 0.02, 'max_depth': 9, 'min_data_in_leaf': 32}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:46,879]\u001b[0m Trial 96 finished with value: 204.34642096224977 and parameters: {'num_leaves': 2, 'learning_rate': 0.03, 'max_depth': 4, 'min_data_in_leaf': 21}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:47,134]\u001b[0m Trial 97 finished with value: 210.95352239811956 and parameters: {'num_leaves': 15, 'learning_rate': 0.04, 'max_depth': 9, 'min_data_in_leaf': 31}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:47,257]\u001b[0m Trial 98 finished with value: 207.59841508864992 and parameters: {'num_leaves': 6, 'learning_rate': 0.02, 'max_depth': 9, 'min_data_in_leaf': 38}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n",
      "\u001b[32m[I 2023-01-15 20:34:47,382]\u001b[0m Trial 99 finished with value: 199.88091648496157 and parameters: {'num_leaves': 5, 'learning_rate': 0.03, 'max_depth': 9, 'min_data_in_leaf': 17}. Best is trial 15 with value: 196.37995075801047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial: #15 196.37995075801047 {'num_leaves': 3, 'learning_rate': 0.03, 'max_depth': 8, 'min_data_in_leaf': 33}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param_grid = {\n",
    "        'verbose': -1,\n",
    "        'boosting': 'gbdt', # gbdt, rf, dart, goss\n",
    "        'objective': 'regression_l1',\n",
    "        'early_stopping_round': 100,\n",
    "        'metric': ['MAE'],\n",
    "        'num_threads': 10,\n",
    "        ### tuning\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 99),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.1, step=0.01),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
    "        'feature_pre_filter': False,\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 40),\n",
    "        # 'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        # 'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        # 'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        # 'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        # 'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "    }\n",
    "\n",
    "    lightgbm_model(param_grid, num_boost_round=3000, features=X.columns.to_list(), log=False)\n",
    "\n",
    "    y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    # rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return mae\n",
    " \n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    " \n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print(f'Best trial: #{study.best_trial.number} {study.best_trial.values[0]}', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best trial params: {'num_leaves': 3, 'learning_rate': 0.03, 'max_depth': 8, 'min_data_in_leaf': 33}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[856]\tvalid_0's l1: 196.38\n",
      "Evaluated only: l1\n",
      "\n",
      "**********\n",
      "model test MAE (RMSE): 196.38 (355.2943)\n",
      "manager test MAE (RMSE): 218.1555 (367.549)\n",
      "analyst test MAE (RMSE): 283.9965 (432.3639)\n",
      "\n",
      "**********\n",
      "model vs manager: edge -0.1 | t-stat -1.039 p-value 0.299\n",
      "model vs analyst: edge -0.309 | t-stat -3.974 p-value 0.0\n",
      "\n",
      "************************************\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using best trial params: {study.best_trial.params}\")\n",
    "\n",
    "param_opt = {\n",
    "    'verbose': -1,\n",
    "    'boosting': 'gbdt', # gbdt, rf, dart, goss\n",
    "    'objective': 'regression_l1',\n",
    "    'num_leaves': 20, \n",
    "    'learning_rate': 0.05,\n",
    "    'early_stopping_round': 100,\n",
    "    'metric': ['MAE'],\n",
    "    'first_metric_only': True,\n",
    "    'num_threads': 10\n",
    "    }\n",
    "param_opt.update(study.best_trial.params) # use best optuna parameters\n",
    "\n",
    "lightgbm_model(param_opt, num_boost_round=3000, features=X.columns.to_list())\n",
    "model_performance(y_pred=y_pred, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study_et' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m mae_model_test \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(mean_absolute_error(y_test, y_pred), \u001b[39m4\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[39m# et\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m et_model()\n\u001b[0;32m     16\u001b[0m mae_et_test \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(mean_absolute_error(y_test, y_pred_et), \u001b[39m4\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[39m# xgb\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 40\u001b[0m, in \u001b[0;36met_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mglobal\u001b[39;00m y_pred_et\n\u001b[0;32m     31\u001b[0m param_et \u001b[39m=\u001b[39m {\n\u001b[0;32m     32\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m167\u001b[39m, \n\u001b[0;32m     33\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m44\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrandom_state\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m123\u001b[39m\n\u001b[0;32m     39\u001b[0m     }\n\u001b[1;32m---> 40\u001b[0m param_et\u001b[39m.\u001b[39mupdate(study_et\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams)\n\u001b[0;32m     43\u001b[0m et \u001b[39m=\u001b[39m ExtraTreesRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparam_et)\n\u001b[0;32m     44\u001b[0m \u001b[39m# train the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'study_et' is not defined"
     ]
    }
   ],
   "source": [
    "## automatic split\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size=0.2, shuffle=False)\n",
    "\n",
    "# manager / analyst error\n",
    "manager_analyst_accuracy(actual_var=\"actual_revenue\", manager_var=\"revenue_guidance_average\", analyst_var=\"analyst_mean_guidance_date\")\n",
    "# target encoding\n",
    "target_encoding(cat_columns=categoricals_targetencode, shrinking_factor=0.0)\n",
    "\n",
    "# model predictions\n",
    "# lgbm\n",
    "lightgbm_model(param, num_boost_round=3000, features=X.columns.to_list(), log=False)\n",
    "mae_model_test = round(mean_absolute_error(y_test, y_pred), 4)\n",
    "# et\n",
    "et_model()\n",
    "mae_et_test = round(mean_absolute_error(y_test, y_pred_et), 4)\n",
    "# xgb\n",
    "xgb_model()\n",
    "mae_xgb_test = round(mean_absolute_error(y_test, y_pred_xgb), 4)\n",
    "# rf\n",
    "rf_model()\n",
    "mae_rf_test = round(mean_absolute_error(y_test, y_pred_rf), 4)\n",
    "\n",
    "# sort models by MAE\n",
    "df_models = pd.DataFrame({\"model\": [\"lgbm\", \"et\", \"xgb\", \"rf\"], \"MAE\": [mae_model_test, mae_et_test, mae_xgb_test, mae_rf_test]})\n",
    "df_models = df_models.sort_values(by=[\"MAE\"])\n",
    "\n",
    "# take a simple weighted average\n",
    "y_pred_avg = ensemble_weights[\"weight_model1\"]*y_pred + ensemble_weights[\"weight_model2\"]*y_pred_et + ensemble_weights[\"weight_model3\"]*y_pred_xgb + ensemble_weights[\"weight_model4\"]*y_pred_rf\n",
    "mae_avg_test = round(mean_absolute_error(y_test, y_pred_avg), 4)\n",
    "\n",
    "# add to df\n",
    "df_models = pd.concat([df_models, pd.DataFrame({\"model\": [\"ensemble\"], \"MAE\": mae_avg_test})], axis=0).sort_values(by=[\"MAE\"])\n",
    "df_models\n",
    "\n",
    "model_performance(y_pred=y_pred_avg, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time series split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>features</th>\n",
       "      <th>t_model_manager</th>\n",
       "      <th>p_model_manager</th>\n",
       "      <th>t_model_analyst</th>\n",
       "      <th>p_model_analyst</th>\n",
       "      <th>mae_model_test</th>\n",
       "      <th>mae_manager_test</th>\n",
       "      <th>mae_analyst_test</th>\n",
       "      <th>indices_train_start</th>\n",
       "      <th>indices_train_end</th>\n",
       "      <th>indices_test_start</th>\n",
       "      <th>indices_test_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.700</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>0.647</td>\n",
       "      <td>310.3792</td>\n",
       "      <td>289.0314</td>\n",
       "      <td>334.8701</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>269</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.827</td>\n",
       "      <td>172.3078</td>\n",
       "      <td>158.1464</td>\n",
       "      <td>167.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>535</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>0.390</td>\n",
       "      <td>-2.150</td>\n",
       "      <td>0.032</td>\n",
       "      <td>141.7654</td>\n",
       "      <td>163.4719</td>\n",
       "      <td>200.1672</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>801</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>-1.286</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-1.650</td>\n",
       "      <td>0.100</td>\n",
       "      <td>169.7058</td>\n",
       "      <td>309.1371</td>\n",
       "      <td>347.4998</td>\n",
       "      <td>0</td>\n",
       "      <td>1066</td>\n",
       "      <td>1067</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-1.512</td>\n",
       "      <td>0.131</td>\n",
       "      <td>190.7941</td>\n",
       "      <td>211.0936</td>\n",
       "      <td>259.9908</td>\n",
       "      <td>0</td>\n",
       "      <td>1332</td>\n",
       "      <td>1333</td>\n",
       "      <td>1598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  features  t_model_manager  p_model_manager  t_model_analyst  \\\n",
       "0     0        26            0.386            0.700           -0.459   \n",
       "1     1        26            0.580            0.562            0.219   \n",
       "2     2        26           -0.860            0.390           -2.150   \n",
       "3     3        26           -1.286            0.199           -1.650   \n",
       "4     4        26           -0.466            0.641           -1.512   \n",
       "\n",
       "   p_model_analyst  mae_model_test  mae_manager_test  mae_analyst_test  \\\n",
       "0            0.647        310.3792          289.0314          334.8701   \n",
       "1            0.827        172.3078          158.1464          167.0000   \n",
       "2            0.032        141.7654          163.4719          200.1672   \n",
       "3            0.100        169.7058          309.1371          347.4998   \n",
       "4            0.131        190.7941          211.0936          259.9908   \n",
       "\n",
       "   indices_train_start  indices_train_end  indices_test_start  \\\n",
       "0                    0                268                 269   \n",
       "1                    0                534                 535   \n",
       "2                    0                800                 801   \n",
       "3                    0               1066                1067   \n",
       "4                    0               1332                1333   \n",
       "\n",
       "   indices_test_end  \n",
       "0               534  \n",
       "1               800  \n",
       "2              1066  \n",
       "3              1332  \n",
       "4              1598  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "mae_model_test      196.99046\n",
       "mae_manager_test    226.17608\n",
       "mae_analyst_test    261.90558\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE edge: manager -0.129 | analyst -0.2479\n"
     ]
    }
   ],
   "source": [
    "# create results dict\n",
    "results_dict = {} \n",
    "results_vars_names = [\"fold\", \"features\", \"t_model_manager\", \"p_model_manager\", \"t_model_analyst\", \"p_model_analyst\", \"mae_model_test\", \"mae_manager_test\", \"mae_analyst_test\", \"indices_train_start\", \"indices_train_end\", \"indices_test_start\", \"indices_test_end\"] #, \"rmse_model_test\", \"rmse_manager_test\", \"rmse_analyst_test\"\n",
    "for i in results_vars_names:\n",
    "    results_dict[i] = []\n",
    "\n",
    "# time series splits\n",
    "tss = TimeSeriesSplit(n_splits=5)\n",
    "for fold, (indices_train, indices_test) in enumerate(tss.split(X)):\n",
    "    print(f\"Fold: {fold}\")\n",
    "    # print(\"train indices:\", indices_train)\n",
    "    # print(\"test indices:\", indices_test)\n",
    "    X_train, X_test = X.iloc[indices_train], X.iloc[indices_test]\n",
    "    y_train, y_test = y.iloc[indices_train], y.iloc[indices_test]\n",
    "    # print(f\"complete: {X.shape} train: {X_train.shape} test: {X_test.shape}\")\n",
    "\n",
    "    # target encoding\n",
    "    target_encoding(cat_columns=categoricals_targetencode, shrinking_factor=0.0)\n",
    "    # manager / analyst error\n",
    "    manager_analyst_accuracy(actual_var=\"actual_revenue\", manager_var=\"revenue_guidance_average\", analyst_var=\"analyst_mean_guidance_date\")\n",
    "    # model \n",
    "    lightgbm_model(param, num_boost_round=3000, features=X.columns.to_list(), log=False) # param_opt for most recent optuna params\n",
    "    model_performance(y_pred=y_pred, print_results=False)\n",
    "\n",
    "    # results\n",
    "    results_vars = [fold, X_test.shape[1], round(ttest_model_manager[0], 3), round(ttest_model_manager[1], 3), round(ttest_model_analyst[0], 3), round(ttest_model_analyst[1], 3), mae_model_test, mae_manager_test, mae_analyst_test, indices_train[0], indices_train[-1], indices_test[0], indices_test[-1]] #, rmse_model_test, rmse_manager_test, rmse_analyst_test\n",
    "    for index, value in enumerate(results_vars_names): # append results to dict\n",
    "        results_dict[value].append(results_vars[index])\n",
    "\n",
    "# df with results for each fold\n",
    "df_tss = pd.DataFrame(results_dict)\n",
    "df_tss\n",
    "# average accuracy of all folds\n",
    "df_tss[[\"mae_model_test\", \"mae_manager_test\", \"mae_analyst_test\"]].mean() # MAE\n",
    "# df_tss[[\"rmse_model_test\", \"rmse_manager_test\", \"rmse_analyst_test\"]].mean() # RMSE\n",
    "\n",
    "df_tss_list = df_tss[[\"mae_model_test\", \"mae_manager_test\", \"mae_analyst_test\"]].mean().to_list() # MAE edge\n",
    "print(f\"MAE edge: manager {round((df_tss_list[0] - df_tss_list[1]) / df_tss_list[1], 4)} | analyst {round((df_tss_list[0] - df_tss_list[2]) / df_tss_list[2], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tss optuna hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize mean mae of all folds\n",
    "# (better to select a weak performing fold and just optimize the single fold)\n",
    "def objective_tss(trial):\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    param_cv_grid = {\n",
    "        'verbose': -1,\n",
    "        'boosting': 'gbdt', # gbdt, rf, dart, goss\n",
    "        'objective': 'regression_l1',\n",
    "        'early_stopping_round': 100,\n",
    "        'metric': ['MAE'],\n",
    "        'num_threads': 10,\n",
    "        ### tuning\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 99),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.1, step=0.01),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
    "        'feature_pre_filter': False,\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 40),\n",
    "        # 'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        # 'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        # 'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        # 'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        # 'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "    }\n",
    "\n",
    "    # create empty list\n",
    "    mae_results = []\n",
    "\n",
    "    # time series splits\n",
    "    tss = TimeSeriesSplit(n_splits=5)\n",
    "    for fold, (indices_train, indices_test) in enumerate(tss.split(X)):\n",
    "        # if fold in [2,3,4]:\n",
    "        #     continue\n",
    "        X_train, X_test = X.iloc[indices_train], X.iloc[indices_test]\n",
    "        y_train, y_test = y.iloc[indices_train], y.iloc[indices_test]\n",
    "\n",
    "        # target encoding\n",
    "        target_encoding(cat_columns=categoricals_targetencode, shrinking_factor=0.0)\n",
    "        # manager / analyst error\n",
    "        manager_analyst_accuracy(actual_var=\"actual_revenue\", manager_var=\"revenue_guidance_average\", analyst_var=\"analyst_mean_guidance_date\")\n",
    "\n",
    "        # model \n",
    "        lightgbm_model(param_cv_grid, num_boost_round=3000, features=X.columns.to_list(), log=False) # param_opt for most recent optuna params\n",
    "\n",
    "        # results\n",
    "        mae = mean_absolute_error(y_test, y_pred) # mean_squared_error(y_test, y_pred, squared=False)\n",
    "        mae_results.append(mae)\n",
    "\n",
    "    # objective which should be minimized\n",
    "    mean_mae = sum(mae_results) / len(mae_results)\n",
    "    return mean_mae\n",
    " \n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_tss, n_trials=70)\n",
    " \n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print(f'Best trial: #{study.best_trial.number} {study.best_trial.values[0]}', study.best_trial.params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot timeseriessplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "TRAIN indices: [   0    1    2 ... 2665 2666 2667] \n",
      " TEST indices: [2668 2669 2670 ... 5331 5332 5333]\n",
      "Fold: 1\n",
      "TRAIN indices: [   0    1    2 ... 5331 5332 5333] \n",
      " TEST indices: [5334 5335 5336 ... 7997 7998 7999]\n",
      "Fold: 2\n",
      "TRAIN indices: [   0    1    2 ... 7997 7998 7999] \n",
      " TEST indices: [ 8000  8001  8002 ... 10663 10664 10665]\n",
      "Fold: 3\n",
      "TRAIN indices: [    0     1     2 ... 10663 10664 10665] \n",
      " TEST indices: [10666 10667 10668 ... 13329 13330 13331]\n",
      "Fold: 4\n",
      "TRAIN indices: [    0     1     2 ... 13329 13330 13331] \n",
      " TEST indices: [13332 13333 13334 ... 15995 15996 15997]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.patches import Patch\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "plt.style.use('fivethirtyeight')\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "# Create a sample plot for indices of a cross-validation object\n",
    "def plot_cv_indices(cv, n_splits, X, y, date_col = None):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (12, 4)) # graph size\n",
    "    \n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for fold, (train_index, test_index) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[test_index] = 1\n",
    "        indices[train_index] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [fold + 0] * len(indices),\n",
    "                   c=indices, marker='_', lw=10, cmap=cmap_cv,\n",
    "                   vmin=-0.2, vmax=1.2)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = [i+1 for i in range(5)]\n",
    "    \n",
    "    if date_col is not None:\n",
    "        tick_locations  = ax.get_xticks()\n",
    "        try:\n",
    "            tick_dates = [\" \"] + date_col.iloc[list(tick_locations[1:-1])].astype(str).tolist() + [\" \"] # get_xticks is sometimes larger than the last used index\n",
    "        except:\n",
    "            tick_dates = [\" \"] + date_col.iloc[list(tick_locations[1:-2])].astype(str).tolist() + date_col.iloc[-1:, ].astype(str).tolist() + [\" \"] \n",
    "\n",
    "        tick_locations_str = [str(int(i)) for i in tick_locations]\n",
    "        new_labels = ['\\n\\n'.join(x) for x in zip(list(tick_locations_str), tick_dates) ]\n",
    "        ax.set_xticks(tick_locations)\n",
    "        ax.set_xticklabels(new_labels)\n",
    "    \n",
    "    ax.set(yticks=np.arange(n_splits), yticklabels=yticklabels,\n",
    "           xlabel='Observations', ylabel=\"Fold\",\n",
    "           ylim=[n_splits-0.5, -.5]) # lower/upper limit of y-axis\n",
    "    ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
    "              ['Testing set', 'Training set'], loc=(1.02, .8))\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "\n",
    "# print indices\n",
    "for fold, (train_index, test_index) in enumerate(tss.split(X)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    print(\"TRAIN indices:\", train_index, \"\\n\", \"TEST indices:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "\n",
    "plot_cv_indices(tss, 5, X, y, date_col = df['quarter_guided']) #, date_col = df['quarter_guided']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tss ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n"
     ]
    }
   ],
   "source": [
    "#tss predictions\n",
    "# create empty dict to store prediction arrays for each fold and model\n",
    "tss_blend_preds = {\"y_tests\": [], \"y_manager\": [], \"y_analyst\": [], \"y_preds_lgbm\": [], \"y_preds_xgb\": [], \"y_preds_et\": [], \"y_preds_rf\": []}\n",
    "\n",
    "# time series splits\n",
    "folds = 5\n",
    "tss = TimeSeriesSplit(n_splits=folds)\n",
    "for fold, (indices_train, indices_test) in enumerate(tss.split(X)):\n",
    "    print(f\"Fold: {fold}\")\n",
    "    X_train, X_test = X.iloc[indices_train], X.iloc[indices_test]\n",
    "    y_train, y_test = y.iloc[indices_train], y.iloc[indices_test]\n",
    "\n",
    "    # manager / analyst error\n",
    "    manager_analyst_accuracy(actual_var=\"actual_revenue\", manager_var=\"revenue_guidance_average\", analyst_var=\"analyst_mean_guidance_date\")\n",
    "    # append array of actual values, manager estimates, analyst estimates\n",
    "    tss_blend_preds[\"y_tests\"].append(y_test)\n",
    "    tss_blend_preds[\"y_manager\"].append(X_manager_test)\n",
    "    tss_blend_preds[\"y_analyst\"].append(X_analyst_test)\n",
    "\n",
    "    # target encoding\n",
    "    target_encoding(cat_columns=categoricals_targetencode, shrinking_factor=0.0)\n",
    "\n",
    "    # model predictions for each fold\n",
    "    # lgbm\n",
    "    lightgbm_model(param, num_boost_round=3000, features=X.columns.to_list(), log=False)\n",
    "    tss_blend_preds[\"y_preds_lgbm\"].append(y_pred)\n",
    "    # et\n",
    "    et_model()\n",
    "    tss_blend_preds[\"y_preds_et\"].append(y_pred_et)\n",
    "    # xgb\n",
    "    xgb_model()\n",
    "    tss_blend_preds[\"y_preds_xgb\"].append(y_pred_xgb)\n",
    "    # rf\n",
    "    rf_model()\n",
    "    tss_blend_preds[\"y_preds_rf\"].append(y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae_test_manager</th>\n",
       "      <th>mae_test_analyst</th>\n",
       "      <th>mae_test_ensemble</th>\n",
       "      <th>mae_test_lgbm</th>\n",
       "      <th>mae_test_et</th>\n",
       "      <th>mae_test_xgb</th>\n",
       "      <th>mae_test_rf</th>\n",
       "      <th>p_manager_ensemble</th>\n",
       "      <th>p_manager_lgbm</th>\n",
       "      <th>p_manager_et</th>\n",
       "      <th>p_manager_xgb</th>\n",
       "      <th>p_manager_rf</th>\n",
       "      <th>p_analyst_ensemble</th>\n",
       "      <th>p_analyst_lgbm</th>\n",
       "      <th>p_analyst_et</th>\n",
       "      <th>p_analyst_xgb</th>\n",
       "      <th>p_analyst_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289.03140</td>\n",
       "      <td>334.87010</td>\n",
       "      <td>302.38960</td>\n",
       "      <td>310.37920</td>\n",
       "      <td>331.93240</td>\n",
       "      <td>301.50110</td>\n",
       "      <td>327.3638</td>\n",
       "      <td>0.81020</td>\n",
       "      <td>0.69950</td>\n",
       "      <td>0.45630</td>\n",
       "      <td>0.82090</td>\n",
       "      <td>0.51430</td>\n",
       "      <td>0.54550</td>\n",
       "      <td>0.64660</td>\n",
       "      <td>0.95800</td>\n",
       "      <td>0.53040</td>\n",
       "      <td>0.89520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158.14640</td>\n",
       "      <td>167.00000</td>\n",
       "      <td>173.08940</td>\n",
       "      <td>172.30780</td>\n",
       "      <td>182.52880</td>\n",
       "      <td>222.88490</td>\n",
       "      <td>224.2398</td>\n",
       "      <td>0.53950</td>\n",
       "      <td>0.56210</td>\n",
       "      <td>0.32060</td>\n",
       "      <td>0.01280</td>\n",
       "      <td>0.01470</td>\n",
       "      <td>0.80140</td>\n",
       "      <td>0.82700</td>\n",
       "      <td>0.52460</td>\n",
       "      <td>0.03080</td>\n",
       "      <td>0.03370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163.47190</td>\n",
       "      <td>200.16720</td>\n",
       "      <td>140.57920</td>\n",
       "      <td>141.76540</td>\n",
       "      <td>167.69050</td>\n",
       "      <td>178.06750</td>\n",
       "      <td>191.4950</td>\n",
       "      <td>0.36470</td>\n",
       "      <td>0.39020</td>\n",
       "      <td>0.86980</td>\n",
       "      <td>0.59390</td>\n",
       "      <td>0.30910</td>\n",
       "      <td>0.02870</td>\n",
       "      <td>0.03210</td>\n",
       "      <td>0.24030</td>\n",
       "      <td>0.44870</td>\n",
       "      <td>0.76740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>309.13710</td>\n",
       "      <td>347.49980</td>\n",
       "      <td>167.41970</td>\n",
       "      <td>169.70580</td>\n",
       "      <td>180.56720</td>\n",
       "      <td>187.47030</td>\n",
       "      <td>201.8997</td>\n",
       "      <td>0.19380</td>\n",
       "      <td>0.19950</td>\n",
       "      <td>0.24320</td>\n",
       "      <td>0.26560</td>\n",
       "      <td>0.33680</td>\n",
       "      <td>0.09680</td>\n",
       "      <td>0.09990</td>\n",
       "      <td>0.12760</td>\n",
       "      <td>0.14080</td>\n",
       "      <td>0.18970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211.09360</td>\n",
       "      <td>259.99080</td>\n",
       "      <td>184.39980</td>\n",
       "      <td>190.79410</td>\n",
       "      <td>197.61780</td>\n",
       "      <td>212.16490</td>\n",
       "      <td>196.7592</td>\n",
       "      <td>0.53350</td>\n",
       "      <td>0.64110</td>\n",
       "      <td>0.75480</td>\n",
       "      <td>0.98010</td>\n",
       "      <td>0.74230</td>\n",
       "      <td>0.09450</td>\n",
       "      <td>0.13110</td>\n",
       "      <td>0.16990</td>\n",
       "      <td>0.28940</td>\n",
       "      <td>0.16810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>226.17608</td>\n",
       "      <td>261.90558</td>\n",
       "      <td>193.57554</td>\n",
       "      <td>196.99046</td>\n",
       "      <td>212.06734</td>\n",
       "      <td>220.41774</td>\n",
       "      <td>228.3515</td>\n",
       "      <td>0.48834</td>\n",
       "      <td>0.49848</td>\n",
       "      <td>0.52894</td>\n",
       "      <td>0.53466</td>\n",
       "      <td>0.38344</td>\n",
       "      <td>0.31338</td>\n",
       "      <td>0.34734</td>\n",
       "      <td>0.40408</td>\n",
       "      <td>0.28802</td>\n",
       "      <td>0.41082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mae_test_manager  mae_test_analyst  mae_test_ensemble  mae_test_lgbm  \\\n",
       "0            289.03140         334.87010          302.38960      310.37920   \n",
       "1            158.14640         167.00000          173.08940      172.30780   \n",
       "2            163.47190         200.16720          140.57920      141.76540   \n",
       "3            309.13710         347.49980          167.41970      169.70580   \n",
       "4            211.09360         259.99080          184.39980      190.79410   \n",
       "mean         226.17608         261.90558          193.57554      196.99046   \n",
       "\n",
       "      mae_test_et  mae_test_xgb  mae_test_rf  p_manager_ensemble  \\\n",
       "0       331.93240     301.50110     327.3638             0.81020   \n",
       "1       182.52880     222.88490     224.2398             0.53950   \n",
       "2       167.69050     178.06750     191.4950             0.36470   \n",
       "3       180.56720     187.47030     201.8997             0.19380   \n",
       "4       197.61780     212.16490     196.7592             0.53350   \n",
       "mean    212.06734     220.41774     228.3515             0.48834   \n",
       "\n",
       "      p_manager_lgbm  p_manager_et  p_manager_xgb  p_manager_rf  \\\n",
       "0            0.69950       0.45630        0.82090       0.51430   \n",
       "1            0.56210       0.32060        0.01280       0.01470   \n",
       "2            0.39020       0.86980        0.59390       0.30910   \n",
       "3            0.19950       0.24320        0.26560       0.33680   \n",
       "4            0.64110       0.75480        0.98010       0.74230   \n",
       "mean         0.49848       0.52894        0.53466       0.38344   \n",
       "\n",
       "      p_analyst_ensemble  p_analyst_lgbm  p_analyst_et  p_analyst_xgb  \\\n",
       "0                0.54550         0.64660       0.95800        0.53040   \n",
       "1                0.80140         0.82700       0.52460        0.03080   \n",
       "2                0.02870         0.03210       0.24030        0.44870   \n",
       "3                0.09680         0.09990       0.12760        0.14080   \n",
       "4                0.09450         0.13110       0.16990        0.28940   \n",
       "mean             0.31338         0.34734       0.40408        0.28802   \n",
       "\n",
       "      p_analyst_rf  \n",
       "0          0.89520  \n",
       "1          0.03370  \n",
       "2          0.76740  \n",
       "3          0.18970  \n",
       "4          0.16810  \n",
       "mean       0.41082  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.14413787700273153"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.26089570142033636"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tss ensemble results\n",
    "\n",
    "# create dict with arrays of actual/manager/analyst/models\n",
    "# blend_results_dict = {}\n",
    "# for mae_model in [key.split(\"_\")[-1] for key, value in tss_blend_preds.items()][1:]:\n",
    "#     blend_results_dict[\"mae_test_\" + mae_model] = []\n",
    "# blend_results_dict.update({\"mae_test_ensemble\": []})\n",
    "\n",
    "blend_results_dict = {'mae_test_manager': [], 'mae_test_analyst': [], 'mae_test_ensemble': [], 'mae_test_lgbm': [], 'mae_test_et': [], 'mae_test_xgb': [], 'mae_test_rf': [], 'p_manager_ensemble': [], 'p_manager_lgbm': [], 'p_manager_et': [], 'p_manager_xgb': [], 'p_manager_rf': [], 'p_analyst_ensemble': [], 'p_analyst_lgbm': [], 'p_analyst_et': [], 'p_analyst_xgb': [], 'p_analyst_rf': []}\n",
    "\n",
    "ensemble_weights = {'weight_model1': 0.63, 'weight_model2': 0.22, 'weight_model3': 0.15, 'weight_model4': 0.0} # manager; optuna see cell below\n",
    "\n",
    "# iterate through folds\n",
    "for fold in range(0, folds):\n",
    "    ## calc mae for the ensemble model\n",
    "    # ensemble new predictions based on weighted average of the 4 models\n",
    "    y_pred_ensemble = ensemble_weights[\"weight_model1\"]*tss_blend_preds[\"y_preds_lgbm\"][fold] + ensemble_weights[\"weight_model2\"]*tss_blend_preds[\"y_preds_et\"][fold] + ensemble_weights[\"weight_model3\"]*tss_blend_preds[\"y_preds_xgb\"][fold] + ensemble_weights[\"weight_model4\"]*tss_blend_preds[\"y_preds_rf\"][fold] # take a simple weighted average\n",
    "    mae_ensemble = round(mean_absolute_error(tss_blend_preds[\"y_tests\"][fold], y_pred_ensemble), 4)\n",
    "\n",
    "    blend_results_dict[\"mae_test_ensemble\"].append(mae_ensemble)\n",
    "    # calc ensemble p values\n",
    "    p_manager = round(stats.ttest_ind(a=np.array(abs(y_pred_ensemble-tss_blend_preds[\"y_tests\"][fold])), b=np.array(abs(tss_blend_preds[\"y_manager\"][fold]-tss_blend_preds[\"y_tests\"][fold])), equal_var=False)[1], 4)\n",
    "    blend_results_dict[\"p_manager_ensemble\"].append(p_manager)\n",
    "    p_analyst = round(stats.ttest_ind(a=np.array(abs(y_pred_ensemble-tss_blend_preds[\"y_tests\"][fold])), b=np.array(abs(tss_blend_preds[\"y_analyst\"][fold]-tss_blend_preds[\"y_tests\"][fold])), equal_var=False)[1], 4)\n",
    "    blend_results_dict[\"p_analyst_ensemble\"].append(p_analyst)\n",
    "\n",
    "    # calc mae for manager/analyst/models\n",
    "    for key, value in tss_blend_preds.items():\n",
    "        if \"tests\" in key: # skip actual values key\n",
    "            continue\n",
    "        elif key.__contains__(\"manager\") or key.__contains__(\"analyst\"): # dont calc p value for manager/analyst arrays\n",
    "            # calc mae for manager/analyst/models\n",
    "            mae = round(mean_absolute_error(tss_blend_preds[\"y_tests\"][fold], value[fold]), 4)\n",
    "            # append mae\n",
    "            key_blend_results_dict = \"mae_test_\" + key.split(\"_\")[-1]\n",
    "            blend_results_dict[key_blend_results_dict].append(mae)\n",
    "        else: # calc mae and p value for each model\n",
    "            # calc mae\n",
    "            key_mae_model= \"mae_test_\" + key.split(\"_\")[-1]\n",
    "            mae = round(mean_absolute_error(tss_blend_preds[\"y_tests\"][fold], value[fold]), 4)\n",
    "            blend_results_dict[key_mae_model].append(mae) # append mae\n",
    "            # calc p manager (of whether MAE of model is significantly different than MAE of manager/analyst)\n",
    "            key_p_manager = \"p_manager_\" + key.split(\"_\")[-1] # match key in dict\n",
    "            p_manager = round(stats.ttest_ind(a=np.array(abs(value[fold]-tss_blend_preds[\"y_tests\"][fold])), b=np.array(abs(tss_blend_preds[\"y_manager\"][fold]-tss_blend_preds[\"y_tests\"][fold])), equal_var=False)[1], 4)\n",
    "            blend_results_dict[key_p_manager].append(p_manager) # append mae\n",
    "            # calc p analyst\n",
    "            key_p_analyst = \"p_analyst_\" + key.split(\"_\")[-1] # match key in dict\n",
    "            p_analyst = round(stats.ttest_ind(a=np.array(abs(value[fold]-tss_blend_preds[\"y_tests\"][fold])), b=np.array(abs(tss_blend_preds[\"y_analyst\"][fold]-tss_blend_preds[\"y_tests\"][fold])), equal_var=False)[1], 4)\n",
    "            blend_results_dict[key_p_analyst].append(p_analyst) # append mae\n",
    "\n",
    "df_tss_blend = pd.DataFrame(blend_results_dict)\n",
    "df_tss_blend.loc['mean'] = df_tss_blend.mean() # add mean to each col\n",
    "df_tss_blend\n",
    "\n",
    "(df_tss_blend[\"mae_test_ensemble\"].mean() - df_tss_blend[\"mae_test_manager\"].mean()) / df_tss_blend[\"mae_test_manager\"].mean()\n",
    "(df_tss_blend[\"mae_test_ensemble\"].mean() - df_tss_blend[\"mae_test_analyst\"].mean()) / df_tss_blend[\"mae_test_analyst\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 300\n",
      "Best trial: #28 193.57554 {'weight_model1': 0.63, 'weight_model2': 0.22, 'weight_model3': 0.15, 'weight_model4': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# minimize the average MAE of the ensemble model over all folds by adjusting the weights of the model's components\n",
    "def objective_blend(trial):\n",
    "    weight_model1 = trial.suggest_float('weight_model1', 0.5, 1, step=0.01)\n",
    "    weight_model2 = trial.suggest_float('weight_model2', 0, (1 - weight_model1), step=0.01)\n",
    "    weight_model3 = trial.suggest_float('weight_model3', 0, (1 - weight_model1 - weight_model2), step=0.01)\n",
    "    weight_model4 = (1-weight_model1-weight_model2-weight_model3)\n",
    "\n",
    "    blend_results_dict = {'mae_test_manager': [], 'mae_test_analyst': [], 'mae_test_ensemble': [], 'mae_test_lgbm': [], 'mae_test_et': [], 'mae_test_xgb': [], 'mae_test_rf': []}\n",
    "\n",
    "    ensemble_weights = {'weight_model1': weight_model1, 'weight_model2': weight_model2, 'weight_model3': weight_model3, 'weight_model4': weight_model4}\n",
    "\n",
    "    # iterate through folds\n",
    "    for fold in range(0, folds):\n",
    "        # if fold in [1, 2,4]:\n",
    "        #     continue\n",
    "        # calc mae for the ensemble model\n",
    "        y_pred_ensemble = ensemble_weights[\"weight_model1\"]*tss_blend_preds[\"y_preds_lgbm\"][fold] + ensemble_weights[\"weight_model2\"]*tss_blend_preds[\"y_preds_et\"][fold] + ensemble_weights[\"weight_model3\"]*tss_blend_preds[\"y_preds_xgb\"][fold] + ensemble_weights[\"weight_model4\"]*tss_blend_preds[\"y_preds_rf\"][fold] # take a simple weighted average\n",
    "        mae_ensemble = round(mean_absolute_error(tss_blend_preds[\"y_tests\"][fold], y_pred_ensemble), 4)\n",
    "        blend_results_dict[\"mae_test_ensemble\"].append(mae_ensemble)\n",
    "\n",
    "        # calc mae for manager/analyst/models\n",
    "        for key, value in tss_blend_preds.items():\n",
    "            if \"tests\" in key: # skip actual values key\n",
    "                continue\n",
    "            else: # add prediction array of each model for the consecutive models\n",
    "                # calc mae for manager/analyst/models\n",
    "                mae = round(mean_absolute_error(tss_blend_preds[\"y_tests\"][fold], value[fold]), 4)\n",
    "                # append mae\n",
    "                key_blend_results_dict = \"mae_test_\" + key.split(\"_\")[-1]\n",
    "                blend_results_dict[key_blend_results_dict].append(mae)\n",
    "        \n",
    "            \n",
    "    df_tss_blend = pd.DataFrame(blend_results_dict)\n",
    "    return df_tss_blend[\"mae_test_ensemble\"].mean()\n",
    " \n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_blend = optuna.create_study(direction='minimize')\n",
    "study_blend.optimize(objective_blend, n_trials=300)\n",
    "\n",
    "blend_dict_opt = study_blend.best_trial.params\n",
    "blend_dict_opt[\"weight_model4\"] = round((1-blend_dict_opt[\"weight_model1\"]-blend_dict_opt[\"weight_model2\"]-blend_dict_opt[\"weight_model3\"]),2)\n",
    " \n",
    "print('Number of finished trials:', len(study_blend.trials))\n",
    "print(f'Best trial: #{study_blend.best_trial.number} {study_blend.best_trial.values[0]}', blend_dict_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "# https://pycaret.readthedocs.io/en/stable/api/regression.html\n",
    "\n",
    "setup_caret = setup(data = pd.concat([X, y], axis=1),\n",
    "                target = 'actual_revenue',\n",
    "                train_size = 0.8,\n",
    "                data_split_shuffle = False,\n",
    "                fold_strategy = 'timeseries', # 'kfold'\n",
    "                fold = 5,\n",
    "                fold_shuffle = False,\n",
    "                preprocess = True,\n",
    "                # numeric_features = forecast_feature + floats + categoricals_targetencode,\n",
    "                # categorical_features = categoricals,\n",
    "                # remove_multicollinearity = True,\n",
    "                # normalize = True,\n",
    "                # normalize_method = 'robust', # 'zscore\n",
    "                # remove_outliers = True,\n",
    "                # outliers_threshold = 0.05, \n",
    "                # pca = True,\n",
    "                # transform_target = True,\n",
    "                silent = False)\n",
    "\n",
    "# pycaret.regression.get_config(\"X\")\n",
    "# pycaret.regression.get_config(\"X_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_78df1 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_78df1_row0_col0, #T_78df1_row0_col2, #T_78df1_row0_col3, #T_78df1_row0_col4, #T_78df1_row1_col0, #T_78df1_row1_col1, #T_78df1_row1_col2, #T_78df1_row1_col3, #T_78df1_row1_col4, #T_78df1_row1_col5, #T_78df1_row1_col6, #T_78df1_row2_col0, #T_78df1_row2_col1, #T_78df1_row2_col2, #T_78df1_row2_col3, #T_78df1_row2_col4, #T_78df1_row2_col5, #T_78df1_row2_col6, #T_78df1_row3_col0, #T_78df1_row3_col1, #T_78df1_row3_col2, #T_78df1_row3_col3, #T_78df1_row3_col4, #T_78df1_row3_col5, #T_78df1_row3_col6, #T_78df1_row4_col0, #T_78df1_row4_col1, #T_78df1_row4_col5, #T_78df1_row4_col6, #T_78df1_row5_col0, #T_78df1_row5_col1, #T_78df1_row5_col2, #T_78df1_row5_col3, #T_78df1_row5_col4, #T_78df1_row5_col5, #T_78df1_row5_col6, #T_78df1_row6_col0, #T_78df1_row6_col1, #T_78df1_row6_col2, #T_78df1_row6_col3, #T_78df1_row6_col4, #T_78df1_row6_col5, #T_78df1_row6_col6, #T_78df1_row7_col0, #T_78df1_row7_col1, #T_78df1_row7_col2, #T_78df1_row7_col3, #T_78df1_row7_col4, #T_78df1_row7_col5, #T_78df1_row7_col6, #T_78df1_row8_col0, #T_78df1_row8_col1, #T_78df1_row8_col2, #T_78df1_row8_col3, #T_78df1_row8_col4, #T_78df1_row8_col5, #T_78df1_row8_col6, #T_78df1_row9_col0, #T_78df1_row9_col1, #T_78df1_row9_col2, #T_78df1_row9_col3, #T_78df1_row9_col4, #T_78df1_row9_col5, #T_78df1_row9_col6, #T_78df1_row10_col0, #T_78df1_row10_col1, #T_78df1_row10_col2, #T_78df1_row10_col3, #T_78df1_row10_col4, #T_78df1_row10_col5, #T_78df1_row10_col6, #T_78df1_row11_col0, #T_78df1_row11_col1, #T_78df1_row11_col2, #T_78df1_row11_col3, #T_78df1_row11_col4, #T_78df1_row11_col5, #T_78df1_row11_col6, #T_78df1_row12_col0, #T_78df1_row12_col1, #T_78df1_row12_col2, #T_78df1_row12_col3, #T_78df1_row12_col4, #T_78df1_row12_col5, #T_78df1_row12_col6, #T_78df1_row13_col0, #T_78df1_row13_col1, #T_78df1_row13_col2, #T_78df1_row13_col3, #T_78df1_row13_col4, #T_78df1_row13_col5, #T_78df1_row13_col6, #T_78df1_row14_col0, #T_78df1_row14_col1, #T_78df1_row14_col2, #T_78df1_row14_col3, #T_78df1_row14_col4, #T_78df1_row14_col5, #T_78df1_row14_col6, #T_78df1_row15_col0, #T_78df1_row15_col1, #T_78df1_row15_col2, #T_78df1_row15_col3, #T_78df1_row15_col4, #T_78df1_row15_col5, #T_78df1_row15_col6, #T_78df1_row16_col0, #T_78df1_row16_col1, #T_78df1_row16_col2, #T_78df1_row16_col3, #T_78df1_row16_col4, #T_78df1_row16_col5, #T_78df1_row16_col6, #T_78df1_row17_col0, #T_78df1_row17_col1, #T_78df1_row17_col2, #T_78df1_row17_col3, #T_78df1_row17_col4, #T_78df1_row17_col5, #T_78df1_row17_col6, #T_78df1_row18_col0, #T_78df1_row18_col1, #T_78df1_row18_col2, #T_78df1_row18_col3, #T_78df1_row18_col4, #T_78df1_row18_col5, #T_78df1_row18_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_78df1_row0_col1, #T_78df1_row0_col5, #T_78df1_row0_col6, #T_78df1_row4_col2, #T_78df1_row4_col3, #T_78df1_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_78df1_row0_col7, #T_78df1_row1_col7, #T_78df1_row2_col7, #T_78df1_row3_col7, #T_78df1_row4_col7, #T_78df1_row5_col7, #T_78df1_row6_col7, #T_78df1_row7_col7, #T_78df1_row8_col7, #T_78df1_row9_col7, #T_78df1_row10_col7, #T_78df1_row11_col7, #T_78df1_row12_col7, #T_78df1_row13_col7, #T_78df1_row14_col7, #T_78df1_row15_col7, #T_78df1_row16_col7, #T_78df1_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_78df1_row18_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_78df1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_78df1_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_78df1_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_78df1_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_78df1_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_78df1_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_78df1_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_78df1_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_78df1_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_78df1_row0_col0\" class=\"data row0 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_78df1_row0_col1\" class=\"data row0 col1\" >16.1782</td>\n",
       "      <td id=\"T_78df1_row0_col2\" class=\"data row0 col2\" >2301.1752</td>\n",
       "      <td id=\"T_78df1_row0_col3\" class=\"data row0 col3\" >47.9706</td>\n",
       "      <td id=\"T_78df1_row0_col4\" class=\"data row0 col4\" >0.9858</td>\n",
       "      <td id=\"T_78df1_row0_col5\" class=\"data row0 col5\" >0.1042</td>\n",
       "      <td id=\"T_78df1_row0_col6\" class=\"data row0 col6\" >0.0549</td>\n",
       "      <td id=\"T_78df1_row0_col7\" class=\"data row0 col7\" >16.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_78df1_row1_col0\" class=\"data row1 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_78df1_row1_col1\" class=\"data row1 col1\" >17.0439</td>\n",
       "      <td id=\"T_78df1_row1_col2\" class=\"data row1 col2\" >2645.7986</td>\n",
       "      <td id=\"T_78df1_row1_col3\" class=\"data row1 col3\" >51.4373</td>\n",
       "      <td id=\"T_78df1_row1_col4\" class=\"data row1 col4\" >0.9836</td>\n",
       "      <td id=\"T_78df1_row1_col5\" class=\"data row1 col5\" >0.1087</td>\n",
       "      <td id=\"T_78df1_row1_col6\" class=\"data row1 col6\" >0.0560</td>\n",
       "      <td id=\"T_78df1_row1_col7\" class=\"data row1 col7\" >10.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row2\" class=\"row_heading level0 row2\" >xgboost</th>\n",
       "      <td id=\"T_78df1_row2_col0\" class=\"data row2 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_78df1_row2_col1\" class=\"data row2 col1\" >17.6430</td>\n",
       "      <td id=\"T_78df1_row2_col2\" class=\"data row2 col2\" >2550.2109</td>\n",
       "      <td id=\"T_78df1_row2_col3\" class=\"data row2 col3\" >50.4996</td>\n",
       "      <td id=\"T_78df1_row2_col4\" class=\"data row2 col4\" >0.9842</td>\n",
       "      <td id=\"T_78df1_row2_col5\" class=\"data row2 col5\" >0.1418</td>\n",
       "      <td id=\"T_78df1_row2_col6\" class=\"data row2 col6\" >0.0873</td>\n",
       "      <td id=\"T_78df1_row2_col7\" class=\"data row2 col7\" >10.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row3\" class=\"row_heading level0 row3\" >lightgbm</th>\n",
       "      <td id=\"T_78df1_row3_col0\" class=\"data row3 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_78df1_row3_col1\" class=\"data row3 col1\" >17.8433</td>\n",
       "      <td id=\"T_78df1_row3_col2\" class=\"data row3 col2\" >2180.9052</td>\n",
       "      <td id=\"T_78df1_row3_col3\" class=\"data row3 col3\" >46.7002</td>\n",
       "      <td id=\"T_78df1_row3_col4\" class=\"data row3 col4\" >0.9865</td>\n",
       "      <td id=\"T_78df1_row3_col5\" class=\"data row3 col5\" >0.1531</td>\n",
       "      <td id=\"T_78df1_row3_col6\" class=\"data row3 col6\" >0.1089</td>\n",
       "      <td id=\"T_78df1_row3_col7\" class=\"data row3 col7\" >0.4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row4\" class=\"row_heading level0 row4\" >catboost</th>\n",
       "      <td id=\"T_78df1_row4_col0\" class=\"data row4 col0\" >CatBoost Regressor</td>\n",
       "      <td id=\"T_78df1_row4_col1\" class=\"data row4 col1\" >18.4969</td>\n",
       "      <td id=\"T_78df1_row4_col2\" class=\"data row4 col2\" >2031.3774</td>\n",
       "      <td id=\"T_78df1_row4_col3\" class=\"data row4 col3\" >45.0708</td>\n",
       "      <td id=\"T_78df1_row4_col4\" class=\"data row4 col4\" >0.9874</td>\n",
       "      <td id=\"T_78df1_row4_col5\" class=\"data row4 col5\" >0.1730</td>\n",
       "      <td id=\"T_78df1_row4_col6\" class=\"data row4 col6\" >0.1298</td>\n",
       "      <td id=\"T_78df1_row4_col7\" class=\"data row4 col7\" >100.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row5\" class=\"row_heading level0 row5\" >gbr</th>\n",
       "      <td id=\"T_78df1_row5_col0\" class=\"data row5 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_78df1_row5_col1\" class=\"data row5 col1\" >19.2794</td>\n",
       "      <td id=\"T_78df1_row5_col2\" class=\"data row5 col2\" >2491.8017</td>\n",
       "      <td id=\"T_78df1_row5_col3\" class=\"data row5 col3\" >49.9179</td>\n",
       "      <td id=\"T_78df1_row5_col4\" class=\"data row5 col4\" >0.9846</td>\n",
       "      <td id=\"T_78df1_row5_col5\" class=\"data row5 col5\" >0.2270</td>\n",
       "      <td id=\"T_78df1_row5_col6\" class=\"data row5 col6\" >0.1967</td>\n",
       "      <td id=\"T_78df1_row5_col7\" class=\"data row5 col7\" >29.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row6\" class=\"row_heading level0 row6\" >dt</th>\n",
       "      <td id=\"T_78df1_row6_col0\" class=\"data row6 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_78df1_row6_col1\" class=\"data row6 col1\" >22.6457</td>\n",
       "      <td id=\"T_78df1_row6_col2\" class=\"data row6 col2\" >4243.2298</td>\n",
       "      <td id=\"T_78df1_row6_col3\" class=\"data row6 col3\" >65.1401</td>\n",
       "      <td id=\"T_78df1_row6_col4\" class=\"data row6 col4\" >0.9737</td>\n",
       "      <td id=\"T_78df1_row6_col5\" class=\"data row6 col5\" >0.1318</td>\n",
       "      <td id=\"T_78df1_row6_col6\" class=\"data row6 col6\" >0.0747</td>\n",
       "      <td id=\"T_78df1_row6_col7\" class=\"data row6 col7\" >1.1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row7\" class=\"row_heading level0 row7\" >lasso</th>\n",
       "      <td id=\"T_78df1_row7_col0\" class=\"data row7 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_78df1_row7_col1\" class=\"data row7 col1\" >26.4204</td>\n",
       "      <td id=\"T_78df1_row7_col2\" class=\"data row7 col2\" >7867.1543</td>\n",
       "      <td id=\"T_78df1_row7_col3\" class=\"data row7 col3\" >88.6970</td>\n",
       "      <td id=\"T_78df1_row7_col4\" class=\"data row7 col4\" >0.9513</td>\n",
       "      <td id=\"T_78df1_row7_col5\" class=\"data row7 col5\" >0.2443</td>\n",
       "      <td id=\"T_78df1_row7_col6\" class=\"data row7 col6\" >0.2145</td>\n",
       "      <td id=\"T_78df1_row7_col7\" class=\"data row7 col7\" >8.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row8\" class=\"row_heading level0 row8\" >br</th>\n",
       "      <td id=\"T_78df1_row8_col0\" class=\"data row8 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_78df1_row8_col1\" class=\"data row8 col1\" >26.4227</td>\n",
       "      <td id=\"T_78df1_row8_col2\" class=\"data row8 col2\" >7873.9453</td>\n",
       "      <td id=\"T_78df1_row8_col3\" class=\"data row8 col3\" >88.7353</td>\n",
       "      <td id=\"T_78df1_row8_col4\" class=\"data row8 col4\" >0.9512</td>\n",
       "      <td id=\"T_78df1_row8_col5\" class=\"data row8 col5\" >0.2443</td>\n",
       "      <td id=\"T_78df1_row8_col6\" class=\"data row8 col6\" >0.2146</td>\n",
       "      <td id=\"T_78df1_row8_col7\" class=\"data row8 col7\" >6.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row9\" class=\"row_heading level0 row9\" >en</th>\n",
       "      <td id=\"T_78df1_row9_col0\" class=\"data row9 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_78df1_row9_col1\" class=\"data row9 col1\" >26.4252</td>\n",
       "      <td id=\"T_78df1_row9_col2\" class=\"data row9 col2\" >7866.6025</td>\n",
       "      <td id=\"T_78df1_row9_col3\" class=\"data row9 col3\" >88.6939</td>\n",
       "      <td id=\"T_78df1_row9_col4\" class=\"data row9 col4\" >0.9513</td>\n",
       "      <td id=\"T_78df1_row9_col5\" class=\"data row9 col5\" >0.2435</td>\n",
       "      <td id=\"T_78df1_row9_col6\" class=\"data row9 col6\" >0.2136</td>\n",
       "      <td id=\"T_78df1_row9_col7\" class=\"data row9 col7\" >9.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row10\" class=\"row_heading level0 row10\" >ridge</th>\n",
       "      <td id=\"T_78df1_row10_col0\" class=\"data row10 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_78df1_row10_col1\" class=\"data row10 col1\" >26.6480</td>\n",
       "      <td id=\"T_78df1_row10_col2\" class=\"data row10 col2\" >8225.2754</td>\n",
       "      <td id=\"T_78df1_row10_col3\" class=\"data row10 col3\" >90.6933</td>\n",
       "      <td id=\"T_78df1_row10_col4\" class=\"data row10 col4\" >0.9491</td>\n",
       "      <td id=\"T_78df1_row10_col5\" class=\"data row10 col5\" >0.1824</td>\n",
       "      <td id=\"T_78df1_row10_col6\" class=\"data row10 col6\" >0.1232</td>\n",
       "      <td id=\"T_78df1_row10_col7\" class=\"data row10 col7\" >0.2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row11\" class=\"row_heading level0 row11\" >lar</th>\n",
       "      <td id=\"T_78df1_row11_col0\" class=\"data row11 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_78df1_row11_col1\" class=\"data row11 col1\" >26.7597</td>\n",
       "      <td id=\"T_78df1_row11_col2\" class=\"data row11 col2\" >7916.7120</td>\n",
       "      <td id=\"T_78df1_row11_col3\" class=\"data row11 col3\" >88.9759</td>\n",
       "      <td id=\"T_78df1_row11_col4\" class=\"data row11 col4\" >0.9510</td>\n",
       "      <td id=\"T_78df1_row11_col5\" class=\"data row11 col5\" >0.2580</td>\n",
       "      <td id=\"T_78df1_row11_col6\" class=\"data row11 col6\" >0.2290</td>\n",
       "      <td id=\"T_78df1_row11_col7\" class=\"data row11 col7\" >0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row12\" class=\"row_heading level0 row12\" >omp</th>\n",
       "      <td id=\"T_78df1_row12_col0\" class=\"data row12 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_78df1_row12_col1\" class=\"data row12 col1\" >27.1622</td>\n",
       "      <td id=\"T_78df1_row12_col2\" class=\"data row12 col2\" >8053.4108</td>\n",
       "      <td id=\"T_78df1_row12_col3\" class=\"data row12 col3\" >89.7408</td>\n",
       "      <td id=\"T_78df1_row12_col4\" class=\"data row12 col4\" >0.9501</td>\n",
       "      <td id=\"T_78df1_row12_col5\" class=\"data row12 col5\" >0.2592</td>\n",
       "      <td id=\"T_78df1_row12_col6\" class=\"data row12 col6\" >0.2363</td>\n",
       "      <td id=\"T_78df1_row12_col7\" class=\"data row12 col7\" >0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row13\" class=\"row_heading level0 row13\" >par</th>\n",
       "      <td id=\"T_78df1_row13_col0\" class=\"data row13 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_78df1_row13_col1\" class=\"data row13 col1\" >27.7184</td>\n",
       "      <td id=\"T_78df1_row13_col2\" class=\"data row13 col2\" >7115.6808</td>\n",
       "      <td id=\"T_78df1_row13_col3\" class=\"data row13 col3\" >84.3545</td>\n",
       "      <td id=\"T_78df1_row13_col4\" class=\"data row13 col4\" >0.9559</td>\n",
       "      <td id=\"T_78df1_row13_col5\" class=\"data row13 col5\" >0.1479</td>\n",
       "      <td id=\"T_78df1_row13_col6\" class=\"data row13 col6\" >0.0996</td>\n",
       "      <td id=\"T_78df1_row13_col7\" class=\"data row13 col7\" >0.8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row14\" class=\"row_heading level0 row14\" >lr</th>\n",
       "      <td id=\"T_78df1_row14_col0\" class=\"data row14 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_78df1_row14_col1\" class=\"data row14 col1\" >34.0527</td>\n",
       "      <td id=\"T_78df1_row14_col2\" class=\"data row14 col2\" >8433.3789</td>\n",
       "      <td id=\"T_78df1_row14_col3\" class=\"data row14 col3\" >91.8334</td>\n",
       "      <td id=\"T_78df1_row14_col4\" class=\"data row14 col4\" >0.9478</td>\n",
       "      <td id=\"T_78df1_row14_col5\" class=\"data row14 col5\" >0.4635</td>\n",
       "      <td id=\"T_78df1_row14_col6\" class=\"data row14 col6\" >0.3973</td>\n",
       "      <td id=\"T_78df1_row14_col7\" class=\"data row14 col7\" >2.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row15\" class=\"row_heading level0 row15\" >ada</th>\n",
       "      <td id=\"T_78df1_row15_col0\" class=\"data row15 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_78df1_row15_col1\" class=\"data row15 col1\" >66.8682</td>\n",
       "      <td id=\"T_78df1_row15_col2\" class=\"data row15 col2\" >7792.1082</td>\n",
       "      <td id=\"T_78df1_row15_col3\" class=\"data row15 col3\" >88.2729</td>\n",
       "      <td id=\"T_78df1_row15_col4\" class=\"data row15 col4\" >0.9517</td>\n",
       "      <td id=\"T_78df1_row15_col5\" class=\"data row15 col5\" >0.8949</td>\n",
       "      <td id=\"T_78df1_row15_col6\" class=\"data row15 col6\" >2.7763</td>\n",
       "      <td id=\"T_78df1_row15_col7\" class=\"data row15 col7\" >34.9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row16\" class=\"row_heading level0 row16\" >knn</th>\n",
       "      <td id=\"T_78df1_row16_col0\" class=\"data row16 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_78df1_row16_col1\" class=\"data row16 col1\" >70.5811</td>\n",
       "      <td id=\"T_78df1_row16_col2\" class=\"data row16 col2\" >16382.0850</td>\n",
       "      <td id=\"T_78df1_row16_col3\" class=\"data row16 col3\" >127.9925</td>\n",
       "      <td id=\"T_78df1_row16_col4\" class=\"data row16 col4\" >0.8986</td>\n",
       "      <td id=\"T_78df1_row16_col5\" class=\"data row16 col5\" >0.3603</td>\n",
       "      <td id=\"T_78df1_row16_col6\" class=\"data row16 col6\" >0.3643</td>\n",
       "      <td id=\"T_78df1_row16_col7\" class=\"data row16 col7\" >5.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row17\" class=\"row_heading level0 row17\" >llar</th>\n",
       "      <td id=\"T_78df1_row17_col0\" class=\"data row17 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_78df1_row17_col1\" class=\"data row17 col1\" >101.6190</td>\n",
       "      <td id=\"T_78df1_row17_col2\" class=\"data row17 col2\" >20300.7553</td>\n",
       "      <td id=\"T_78df1_row17_col3\" class=\"data row17 col3\" >142.4807</td>\n",
       "      <td id=\"T_78df1_row17_col4\" class=\"data row17 col4\" >0.8743</td>\n",
       "      <td id=\"T_78df1_row17_col5\" class=\"data row17 col5\" >0.8992</td>\n",
       "      <td id=\"T_78df1_row17_col6\" class=\"data row17 col6\" >2.5362</td>\n",
       "      <td id=\"T_78df1_row17_col7\" class=\"data row17 col7\" >0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78df1_level0_row18\" class=\"row_heading level0 row18\" >dummy</th>\n",
       "      <td id=\"T_78df1_row18_col0\" class=\"data row18 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_78df1_row18_col1\" class=\"data row18 col1\" >297.5199</td>\n",
       "      <td id=\"T_78df1_row18_col2\" class=\"data row18 col2\" >164412.6562</td>\n",
       "      <td id=\"T_78df1_row18_col3\" class=\"data row18 col3\" >405.4783</td>\n",
       "      <td id=\"T_78df1_row18_col4\" class=\"data row18 col4\" >-0.0181</td>\n",
       "      <td id=\"T_78df1_row18_col5\" class=\"data row18 col5\" >1.4968</td>\n",
       "      <td id=\"T_78df1_row18_col6\" class=\"data row18 col6\" >7.6493</td>\n",
       "      <td id=\"T_78df1_row18_col7\" class=\"data row18 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1202f2f6610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# models() # show models\n",
    "\n",
    "models_caret = compare_models(\n",
    "                # include = ['et','rf', 'lightgbm', 'xgboost', 'gbr', 'dt', 'lasso'], \n",
    "                # exclude = ['catboost','tr', 'kr', 'ard', 'ransac', 'svm', 'huber', 'lar', 'ada', 'mlp'], \n",
    "                cross_validation=False, \n",
    "                sort=\"MAE\", \n",
    "                turbo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.fast.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression / lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m lasso \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLasso(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;66;03m# Lasso (less relevant features get less weight)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# lasso = linear_model.Ridge(alpha=10) # Ridge\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m lasso\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m      9\u001b[0m y_pred_lasso \u001b[38;5;241m=\u001b[39m lasso\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# accuracy\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# lasso = linear_model.LinearRegression() # OLS\n",
    "lasso = linear_model.Lasso(alpha=10) # Lasso (less relevant features get less weight)\n",
    "# lasso = linear_model.Ridge(alpha=10) # Ridge\n",
    "\n",
    "# model\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "mae_lasso_test = round(mean_absolute_error(y_test, y_pred_lasso), 4)\n",
    "mae_lasso_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel = 'rbf')\n",
    "\n",
    "# model\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "mae_svr_test = round(mean_absolute_error(y_test, y_pred_svr), 4)\n",
    "mae_svr_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "tree = tree.DecisionTreeRegressor()\n",
    "\n",
    "# train the model\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "mae_tree_test = round(mean_absolute_error(y_test, y_pred_tree), 4)\n",
    "mae_tree_test, mae_lgbm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(tree, max_depth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=9, n_estimators=150, n_jobs=-1,\n",
       "                      random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=9, n_estimators=150, n_jobs=-1,\n",
       "                      random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=9, n_estimators=150, n_jobs=-1,\n",
       "                      random_state=123)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE rf 224.8824\n",
      "MAE lgbm 203.8547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "        n_estimators = 150,\n",
    "        max_depth = 9,\n",
    "        min_samples_leaf = 1,\n",
    "        max_leaf_nodes = None,\n",
    "        n_jobs = -1,\n",
    "        random_state = 123\n",
    "    )\n",
    "\n",
    "# train the model\n",
    "rf.fit(X_train, y_train) # execute train test split cell first\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "mae_rf_test = round(mean_absolute_error(y_test, y_pred_rf), 4)\n",
    "print(f\"MAE rf {mae_rf_test}\")\n",
    "print(f\"MAE lgbm {mae_model_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 14:48:10,918]\u001b[0m A new study created in memory with name: no-name-663f56ad-fa57-4c5c-9c21-5a3df5262ccd\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:11,509]\u001b[0m Trial 0 finished with value: 235.21057833760162 and parameters: {'n_estimators': 268, 'max_depth': 5}. Best is trial 0 with value: 235.21057833760162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:11,748]\u001b[0m Trial 1 finished with value: 232.74296800599214 and parameters: {'n_estimators': 72, 'max_depth': 8}. Best is trial 1 with value: 232.74296800599214.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:12,135]\u001b[0m Trial 2 finished with value: 230.41572818493154 and parameters: {'n_estimators': 73, 'max_depth': 31}. Best is trial 2 with value: 230.41572818493154.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:13,081]\u001b[0m Trial 3 finished with value: 226.3845648341837 and parameters: {'n_estimators': 196, 'max_depth': 27}. Best is trial 3 with value: 226.3845648341837.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:13,352]\u001b[0m Trial 4 finished with value: 224.243406165614 and parameters: {'n_estimators': 57, 'max_depth': 12}. Best is trial 4 with value: 224.243406165614.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:13,756]\u001b[0m Trial 5 finished with value: 223.7623780631618 and parameters: {'n_estimators': 83, 'max_depth': 19}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:14,264]\u001b[0m Trial 6 finished with value: 225.05690906249995 and parameters: {'n_estimators': 96, 'max_depth': 37}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:15,125]\u001b[0m Trial 7 finished with value: 225.69433421597623 and parameters: {'n_estimators': 169, 'max_depth': 27}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:16,365]\u001b[0m Trial 8 finished with value: 228.24011520010478 and parameters: {'n_estimators': 274, 'max_depth': 10}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:17,470]\u001b[0m Trial 9 finished with value: 229.00614706519158 and parameters: {'n_estimators': 295, 'max_depth': 8}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:18,218]\u001b[0m Trial 10 finished with value: 224.4565580274618 and parameters: {'n_estimators': 133, 'max_depth': 18}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:18,503]\u001b[0m Trial 11 finished with value: 227.54379429116125 and parameters: {'n_estimators': 53, 'max_depth': 18}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:19,114]\u001b[0m Trial 12 finished with value: 224.06791220059876 and parameters: {'n_estimators': 121, 'max_depth': 14}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:19,857]\u001b[0m Trial 13 finished with value: 225.36047075480374 and parameters: {'n_estimators': 126, 'max_depth': 17}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:20,585]\u001b[0m Trial 14 finished with value: 223.90312155280208 and parameters: {'n_estimators': 122, 'max_depth': 14}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:21,551]\u001b[0m Trial 15 finished with value: 225.54761428613355 and parameters: {'n_estimators': 171, 'max_depth': 22}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:22,811]\u001b[0m Trial 16 finished with value: 225.83408158051662 and parameters: {'n_estimators': 223, 'max_depth': 23}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:23,450]\u001b[0m Trial 17 finished with value: 231.32078684431318 and parameters: {'n_estimators': 100, 'max_depth': 21}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:24,308]\u001b[0m Trial 18 finished with value: 224.63926238173414 and parameters: {'n_estimators': 157, 'max_depth': 14}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:24,846]\u001b[0m Trial 19 finished with value: 225.25882610526315 and parameters: {'n_estimators': 95, 'max_depth': 32}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:25,308]\u001b[0m Trial 20 finished with value: 250.84745350525668 and parameters: {'n_estimators': 198, 'max_depth': 4}. Best is trial 5 with value: 223.7623780631618.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:26,018]\u001b[0m Trial 21 finished with value: 221.94594525885043 and parameters: {'n_estimators': 136, 'max_depth': 13}. Best is trial 21 with value: 221.94594525885043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:26,847]\u001b[0m Trial 22 finished with value: 230.52350515261605 and parameters: {'n_estimators': 149, 'max_depth': 15}. Best is trial 21 with value: 221.94594525885043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:27,379]\u001b[0m Trial 23 finished with value: 224.8639567232653 and parameters: {'n_estimators': 113, 'max_depth': 10}. Best is trial 21 with value: 221.94594525885043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:28,253]\u001b[0m Trial 24 finished with value: 225.92706684516327 and parameters: {'n_estimators': 140, 'max_depth': 20}. Best is trial 21 with value: 221.94594525885043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:28,809]\u001b[0m Trial 25 finished with value: 228.72429750000003 and parameters: {'n_estimators': 80, 'max_depth': 24}. Best is trial 21 with value: 221.94594525885043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:30,007]\u001b[0m Trial 26 finished with value: 225.74198034297584 and parameters: {'n_estimators': 196, 'max_depth': 16}. Best is trial 21 with value: 221.94594525885043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:30,621]\u001b[0m Trial 27 finished with value: 224.48822061110695 and parameters: {'n_estimators': 110, 'max_depth': 12}. Best is trial 21 with value: 221.94594525885043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:31,198]\u001b[0m Trial 28 finished with value: 222.96290390384266 and parameters: {'n_estimators': 91, 'max_depth': 19}. Best is trial 21 with value: 221.94594525885043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:31,772]\u001b[0m Trial 29 finished with value: 225.64922421348322 and parameters: {'n_estimators': 89, 'max_depth': 26}. Best is trial 21 with value: 221.94594525885043.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 30\n",
      "Best trial: #21 221.94594525885043 {'n_estimators': 136, 'max_depth': 13}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param_grid_rf = {\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": 123,\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 40),\n",
    "            # 'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 60),\n",
    "        }\n",
    "\n",
    "    rf_opt = RandomForestRegressor(**param_grid_rf)\n",
    "\n",
    "    # train the model\n",
    "    rf_opt.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_opt.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test,y_pred_rf)\n",
    "    # rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return mae\n",
    " \n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(objective, n_trials=30)\n",
    " \n",
    "print('Number of finished trials:', len(study_rf.trials))\n",
    "print(f'Best trial: #{study_rf.best_trial.number} {study_rf.best_trial.values[0]}', study_rf.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boruta feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    "\n",
    "# find relevant features\n",
    "feat_selector.fit(X_train.values, y_train.values)\n",
    "\n",
    "# rank features\n",
    "feature_df = pd.DataFrame(X.columns.to_list(), columns=['features'])\n",
    "feature_df['rank']=feat_selector.ranking_\n",
    "feature_df = feature_df.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "feature_df.head()\n",
    "boruta_feats = feature_df[\"features\"].to_list()\n",
    "print(boruta_feats[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extra trees\n",
    "Extra Trees is like a Random Forest, in that it builds multiple trees and splits nodes using random subsets of features, but with two key differences: it does not bootstrap observations (meaning it samples without replacement), and nodes are split on random splits, not best splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesRegressor(max_depth=25, n_estimators=150, n_jobs=-1, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(max_depth=25, n_estimators=150, n_jobs=-1, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesRegressor(max_depth=25, n_estimators=150, n_jobs=-1, random_state=123)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE et 229.7943\n",
      "MAE rf 224.8824\n",
      "MAE lgbm 203.8547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "et = ExtraTreesRegressor(\n",
    "    n_estimators=150, \n",
    "    max_depth=25,\n",
    "    # min_samples_leaf=1, \n",
    "    # min_samples_split=25,\n",
    "    # max_features=150\n",
    "    n_jobs=-1, \n",
    "    random_state=123\n",
    "    )\n",
    "\n",
    "# train the model\n",
    "et.fit(X_train, y_train) # execute train test split cell first\n",
    "y_pred_et = et.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "mae_et_test = round(mean_absolute_error(y_test, y_pred_et), 4)\n",
    "print(f\"MAE et {mae_et_test}\")\n",
    "print(f\"MAE rf {mae_rf_test}\")\n",
    "print(f\"MAE lgbm {mae_model_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 14:52:22,172]\u001b[0m A new study created in memory with name: no-name-d609389a-f528-4849-b456-2911b7b64034\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:22,500]\u001b[0m Trial 0 finished with value: 254.4967515422165 and parameters: {'n_estimators': 286, 'max_depth': 17, 'max_features': 9}. Best is trial 0 with value: 254.4967515422165.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:22,764]\u001b[0m Trial 1 finished with value: 242.0587514858519 and parameters: {'n_estimators': 232, 'max_depth': 24, 'max_features': 13}. Best is trial 1 with value: 242.0587514858519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:23,001]\u001b[0m Trial 2 finished with value: 277.55167446215154 and parameters: {'n_estimators': 251, 'max_depth': 42, 'max_features': 6}. Best is trial 1 with value: 242.0587514858519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:23,093]\u001b[0m Trial 3 finished with value: 534.0710780508906 and parameters: {'n_estimators': 113, 'max_depth': 22, 'max_features': 1}. Best is trial 1 with value: 242.0587514858519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:23,273]\u001b[0m Trial 4 finished with value: 348.8081949949867 and parameters: {'n_estimators': 267, 'max_depth': 4, 'max_features': 21}. Best is trial 1 with value: 242.0587514858519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:23,411]\u001b[0m Trial 5 finished with value: 303.3100127287581 and parameters: {'n_estimators': 153, 'max_depth': 40, 'max_features': 4}. Best is trial 1 with value: 242.0587514858519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:23,531]\u001b[0m Trial 6 finished with value: 246.30349552941178 and parameters: {'n_estimators': 85, 'max_depth': 30, 'max_features': 19}. Best is trial 1 with value: 242.0587514858519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:23,783]\u001b[0m Trial 7 finished with value: 235.69240239457838 and parameters: {'n_estimators': 166, 'max_depth': 44, 'max_features': 26}. Best is trial 7 with value: 235.69240239457838.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:23,972]\u001b[0m Trial 8 finished with value: 334.23388608760814 and parameters: {'n_estimators': 216, 'max_depth': 14, 'max_features': 4}. Best is trial 7 with value: 235.69240239457838.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:24,118]\u001b[0m Trial 9 finished with value: 252.9170491651119 and parameters: {'n_estimators': 134, 'max_depth': 33, 'max_features': 10}. Best is trial 7 with value: 235.69240239457838.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:24,409]\u001b[0m Trial 10 finished with value: 234.55834123015865 and parameters: {'n_estimators': 189, 'max_depth': 50, 'max_features': 25}. Best is trial 10 with value: 234.55834123015865.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:24,712]\u001b[0m Trial 11 finished with value: 235.56588734890116 and parameters: {'n_estimators': 182, 'max_depth': 48, 'max_features': 26}. Best is trial 10 with value: 234.55834123015865.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:25,012]\u001b[0m Trial 12 finished with value: 234.75322956030158 and parameters: {'n_estimators': 199, 'max_depth': 50, 'max_features': 26}. Best is trial 10 with value: 234.55834123015865.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:25,286]\u001b[0m Trial 13 finished with value: 240.8182205940594 and parameters: {'n_estimators': 202, 'max_depth': 50, 'max_features': 20}. Best is trial 10 with value: 234.55834123015865.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:25,379]\u001b[0m Trial 14 finished with value: 236.37802274999999 and parameters: {'n_estimators': 50, 'max_depth': 35, 'max_features': 23}. Best is trial 10 with value: 234.55834123015865.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:25,635]\u001b[0m Trial 15 finished with value: 245.3437537372448 and parameters: {'n_estimators': 196, 'max_depth': 38, 'max_features': 16}. Best is trial 10 with value: 234.55834123015865.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:25,986]\u001b[0m Trial 16 finished with value: 240.30868338541669 and parameters: {'n_estimators': 240, 'max_depth': 46, 'max_features': 23}. Best is trial 10 with value: 234.55834123015865.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:26,195]\u001b[0m Trial 17 finished with value: 244.20921116071418 and parameters: {'n_estimators': 140, 'max_depth': 50, 'max_features': 16}. Best is trial 10 with value: 234.55834123015865.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:26,474]\u001b[0m Trial 18 finished with value: 236.4303431831394 and parameters: {'n_estimators': 172, 'max_depth': 37, 'max_features': 24}. Best is trial 10 with value: 234.55834123015865.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:26,633]\u001b[0m Trial 19 finished with value: 228.10620871621614 and parameters: {'n_estimators': 111, 'max_depth': 42, 'max_features': 17}. Best is trial 19 with value: 228.10620871621614.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:26,777]\u001b[0m Trial 20 finished with value: 227.74545995 and parameters: {'n_estimators': 100, 'max_depth': 43, 'max_features': 17}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:26,916]\u001b[0m Trial 21 finished with value: 237.09446463917521 and parameters: {'n_estimators': 97, 'max_depth': 44, 'max_features': 16}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:27,001]\u001b[0m Trial 22 finished with value: 249.07900641509426 and parameters: {'n_estimators': 53, 'max_depth': 41, 'max_features': 12}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:27,125]\u001b[0m Trial 23 finished with value: 243.2252637827004 and parameters: {'n_estimators': 79, 'max_depth': 29, 'max_features': 18}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:27,362]\u001b[0m Trial 24 finished with value: 228.1062087162162 and parameters: {'n_estimators': 111, 'max_depth': 45, 'max_features': 17}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:27,525]\u001b[0m Trial 25 finished with value: 240.55566376050413 and parameters: {'n_estimators': 119, 'max_depth': 35, 'max_features': 15}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:27,650]\u001b[0m Trial 26 finished with value: 242.5147282746479 and parameters: {'n_estimators': 71, 'max_depth': 44, 'max_features': 18}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:27,813]\u001b[0m Trial 27 finished with value: 231.29746009900987 and parameters: {'n_estimators': 101, 'max_depth': 32, 'max_features': 21}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:27,972]\u001b[0m Trial 28 finished with value: 257.0781616346153 and parameters: {'n_estimators': 130, 'max_depth': 39, 'max_features': 11}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:28,324]\u001b[0m Trial 29 finished with value: 240.29878440476182 and parameters: {'n_estimators': 294, 'max_depth': 46, 'max_features': 14}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:28,433]\u001b[0m Trial 30 finished with value: 266.6258730060612 and parameters: {'n_estimators': 109, 'max_depth': 14, 'max_features': 8}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:28,574]\u001b[0m Trial 31 finished with value: 241.56213968749995 and parameters: {'n_estimators': 96, 'max_depth': 32, 'max_features': 18}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:28,686]\u001b[0m Trial 32 finished with value: 239.55778554258205 and parameters: {'n_estimators': 66, 'max_depth': 24, 'max_features': 21}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:28,833]\u001b[0m Trial 33 finished with value: 243.02434128787874 and parameters: {'n_estimators': 99, 'max_depth': 42, 'max_features': 13}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:29,052]\u001b[0m Trial 34 finished with value: 237.23644072048162 and parameters: {'n_estimators': 152, 'max_depth': 21, 'max_features': 21}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:29,239]\u001b[0m Trial 35 finished with value: 244.16112988442464 and parameters: {'n_estimators': 120, 'max_depth': 26, 'max_features': 19}. Best is trial 20 with value: 227.74545995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:29,368]\u001b[0m Trial 36 finished with value: 226.8199402906977 and parameters: {'n_estimators': 86, 'max_depth': 36, 'max_features': 17}. Best is trial 36 with value: 226.8199402906977.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:29,500]\u001b[0m Trial 37 finished with value: 226.65443545977013 and parameters: {'n_estimators': 87, 'max_depth': 36, 'max_features': 17}. Best is trial 37 with value: 226.65443545977013.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:29,632]\u001b[0m Trial 38 finished with value: 243.06467385057468 and parameters: {'n_estimators': 87, 'max_depth': 36, 'max_features': 14}. Best is trial 37 with value: 226.65443545977013.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:29,736]\u001b[0m Trial 39 finished with value: 246.49324019841268 and parameters: {'n_estimators': 63, 'max_depth': 40, 'max_features': 15}. Best is trial 37 with value: 226.65443545977013.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:29,812]\u001b[0m Trial 40 finished with value: 376.83254724365645 and parameters: {'n_estimators': 82, 'max_depth': 5, 'max_features': 12}. Best is trial 37 with value: 226.65443545977013.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:30,016]\u001b[0m Trial 41 finished with value: 228.65349175170064 and parameters: {'n_estimators': 147, 'max_depth': 43, 'max_features': 17}. Best is trial 37 with value: 226.65443545977013.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:30,186]\u001b[0m Trial 42 finished with value: 227.23835230263157 and parameters: {'n_estimators': 114, 'max_depth': 46, 'max_features': 17}. Best is trial 37 with value: 226.65443545977013.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:30,377]\u001b[0m Trial 43 finished with value: 245.14978325819663 and parameters: {'n_estimators': 122, 'max_depth': 47, 'max_features': 19}. Best is trial 37 with value: 226.65443545977013.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:30,596]\u001b[0m Trial 44 finished with value: 240.8695210122698 and parameters: {'n_estimators': 163, 'max_depth': 41, 'max_features': 15}. Best is trial 37 with value: 226.65443545977013.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:30,740]\u001b[0m Trial 45 finished with value: 226.19772359890115 and parameters: {'n_estimators': 91, 'max_depth': 38, 'max_features': 17}. Best is trial 45 with value: 226.19772359890115.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:30,863]\u001b[0m Trial 46 finished with value: 246.7690057713964 and parameters: {'n_estimators': 74, 'max_depth': 29, 'max_features': 20}. Best is trial 45 with value: 226.19772359890115.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:30,978]\u001b[0m Trial 47 finished with value: 254.8099503977273 and parameters: {'n_estimators': 88, 'max_depth': 38, 'max_features': 9}. Best is trial 45 with value: 226.19772359890115.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:31,053]\u001b[0m Trial 48 finished with value: 468.5302581759721 and parameters: {'n_estimators': 62, 'max_depth': 32, 'max_features': 1}. Best is trial 45 with value: 226.19772359890115.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:52:31,260]\u001b[0m Trial 49 finished with value: 243.74770509469687 and parameters: {'n_estimators': 132, 'max_depth': 35, 'max_features': 19}. Best is trial 45 with value: 226.19772359890115.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 50\n",
      "Best trial: #45 226.19772359890115 {'n_estimators': 91, 'max_depth': 38, 'max_features': 17}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param_grid_et = {\n",
    "            \"n_estimators\": trial.suggest_int('n_estimators', 50, 300),\n",
    "            \"max_depth\": trial.suggest_int('max_depth', 4, 50),\n",
    "            \"max_features\": trial.suggest_int('max_features', 1, X.shape[1]),\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": 123\n",
    "        }\n",
    "\n",
    "    et_opt = ExtraTreesRegressor(**param_grid_et)\n",
    "\n",
    "    # train the model\n",
    "    et_opt.fit(X_train, y_train)\n",
    "    y_pred_et = et_opt.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test,y_pred_et)\n",
    "    return mae\n",
    " \n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study_et = optuna.create_study(direction='minimize')\n",
    "study_et.optimize(objective, n_trials=50)\n",
    " \n",
    "print('Number of finished trials:', len(study_et.trials))\n",
    "print(f'Best trial: #{study_et.best_trial.number} {study_et.best_trial.values[0]}', study_et.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:4760.30294\n",
      "[280]\tvalidation_0-mae:298.07524\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=100,\n",
       "             enable_categorical=True, eval_metric=[&#x27;mae&#x27;], feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.06, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=3000, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=100,\n",
       "             enable_categorical=True, eval_metric=[&#x27;mae&#x27;], feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.06, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=3000, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=100,\n",
       "             enable_categorical=True, eval_metric=['mae'], feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.06, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=3000, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE xgb 297.4029\n",
      "MAE lgbm 203.8547\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "param_xgb = {\n",
    "        \"n_estimators\": 3000,\n",
    "        \"max_depth\": 7,\n",
    "        \"learning_rate\": 0.06,\n",
    "        \"booster\": 'gbtree',\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 1,\n",
    "        \"eval_metric\": [\"mae\"],\n",
    "        \"enable_categorical\": True,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"early_stopping_rounds\": 100, # tries for X more iterations after the first minimum was detected\n",
    "        }\n",
    "# param_xgb.update(study_xgb.best_trial.params) # use best optuna parameters\n",
    "\n",
    "xgb = xgboost.XGBRegressor(**param_xgb)\n",
    "\n",
    "xgb.fit(X_train, y_train,\n",
    "        eval_set = [(X_test, y_test)], #Eval set only to check for overfitting etc. and necessary for early_stopping_rounds!\n",
    "        verbose = 500, # how many iteration steps are displayed. True -> show all \n",
    "        )\n",
    "        \n",
    "# make predictions for test data based on the best test model determined before\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "mae_xgb_test = round(mean_absolute_error(y_test, y_pred_xgb), 4)\n",
    "print(f\"MAE xgb {mae_xgb_test}\")\n",
    "print(f\"MAE lgbm {mae_model_test}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 14:48:47,063]\u001b[0m A new study created in memory with name: no-name-681916a9-39e4-4ca8-915d-75ae631ae70b\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:47,383]\u001b[0m Trial 0 finished with value: 248.8819 and parameters: {'max_depth': 3, 'learning_rate': 0.03}. Best is trial 0 with value: 248.8819.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:48,197]\u001b[0m Trial 1 finished with value: 289.2226 and parameters: {'max_depth': 8, 'learning_rate': 0.04}. Best is trial 0 with value: 248.8819.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:49,020]\u001b[0m Trial 2 finished with value: 289.2226 and parameters: {'max_depth': 8, 'learning_rate': 0.04}. Best is trial 0 with value: 248.8819.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:49,786]\u001b[0m Trial 3 finished with value: 295.1661 and parameters: {'max_depth': 9, 'learning_rate': 0.1}. Best is trial 0 with value: 248.8819.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:50,313]\u001b[0m Trial 4 finished with value: 282.4443 and parameters: {'max_depth': 7, 'learning_rate': 0.09000000000000001}. Best is trial 0 with value: 248.8819.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:51,465]\u001b[0m Trial 5 finished with value: 298.8532 and parameters: {'max_depth': 9, 'learning_rate': 0.04}. Best is trial 0 with value: 248.8819.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:51,674]\u001b[0m Trial 6 finished with value: 246.8694 and parameters: {'max_depth': 3, 'learning_rate': 0.04}. Best is trial 6 with value: 246.8694.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:52,915]\u001b[0m Trial 7 finished with value: 275.7331 and parameters: {'max_depth': 6, 'learning_rate': 0.03}. Best is trial 6 with value: 246.8694.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:53,064]\u001b[0m Trial 8 finished with value: 236.6113 and parameters: {'max_depth': 3, 'learning_rate': 0.1}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:54,122]\u001b[0m Trial 9 finished with value: 290.2518 and parameters: {'max_depth': 9, 'learning_rate': 0.07}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:54,418]\u001b[0m Trial 10 finished with value: 288.14 and parameters: {'max_depth': 5, 'learning_rate': 0.07}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:54,614]\u001b[0m Trial 11 finished with value: 238.0069 and parameters: {'max_depth': 3, 'learning_rate': 0.06}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:54,873]\u001b[0m Trial 12 finished with value: 263.5342 and parameters: {'max_depth': 4, 'learning_rate': 0.06}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:55,095]\u001b[0m Trial 13 finished with value: 264.4792 and parameters: {'max_depth': 4, 'learning_rate': 0.08}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:55,310]\u001b[0m Trial 14 finished with value: 267.2232 and parameters: {'max_depth': 4, 'learning_rate': 0.1}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:55,608]\u001b[0m Trial 15 finished with value: 276.7495 and parameters: {'max_depth': 5, 'learning_rate': 0.06}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:55,785]\u001b[0m Trial 16 finished with value: 242.1775 and parameters: {'max_depth': 3, 'learning_rate': 0.08}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:56,177]\u001b[0m Trial 17 finished with value: 280.5615 and parameters: {'max_depth': 5, 'learning_rate': 0.05}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:56,589]\u001b[0m Trial 18 finished with value: 287.7645 and parameters: {'max_depth': 6, 'learning_rate': 0.08}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:57,099]\u001b[0m Trial 19 finished with value: 273.7876 and parameters: {'max_depth': 4, 'learning_rate': 0.02}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:57,289]\u001b[0m Trial 20 finished with value: 241.2962 and parameters: {'max_depth': 3, 'learning_rate': 0.07}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:57,493]\u001b[0m Trial 21 finished with value: 241.2962 and parameters: {'max_depth': 3, 'learning_rate': 0.07}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:57,655]\u001b[0m Trial 22 finished with value: 243.4731 and parameters: {'max_depth': 3, 'learning_rate': 0.09000000000000001}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:57,938]\u001b[0m Trial 23 finished with value: 270.7414 and parameters: {'max_depth': 4, 'learning_rate': 0.05}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:58,110]\u001b[0m Trial 24 finished with value: 243.4731 and parameters: {'max_depth': 3, 'learning_rate': 0.09000000000000001}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:58,530]\u001b[0m Trial 25 finished with value: 280.5615 and parameters: {'max_depth': 5, 'learning_rate': 0.05}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:58,819]\u001b[0m Trial 26 finished with value: 263.5342 and parameters: {'max_depth': 4, 'learning_rate': 0.06}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:59,013]\u001b[0m Trial 27 finished with value: 241.2962 and parameters: {'max_depth': 3, 'learning_rate': 0.07}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:59,240]\u001b[0m Trial 28 finished with value: 267.2232 and parameters: {'max_depth': 4, 'learning_rate': 0.1}. Best is trial 8 with value: 236.6113.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 14:48:59,418]\u001b[0m Trial 29 finished with value: 242.1775 and parameters: {'max_depth': 3, 'learning_rate': 0.08}. Best is trial 8 with value: 236.6113.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 30\n",
      "Best trial: #8 236.6113 {'max_depth': 3, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb(trial):\n",
    "    param_xgb_grid = {\n",
    "                    \"n_estimators\": 3000,\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
    "                    \"learning_rate\": trial.suggest_float('learning_rate', 0.02, 0.1, step=0.01),\n",
    "                    \"booster\": 'gbtree',\n",
    "                    \"n_jobs\": -1,\n",
    "                    \"random_state\": 1,\n",
    "                    \"eval_metric\": [\"mae\"],\n",
    "                    \"enable_categorical\": True,\n",
    "                    \"tree_method\": \"hist\",\n",
    "                    \"early_stopping_rounds\": 100, # tries for X more iterations after the first minimum was detected\n",
    "                }\n",
    "\n",
    "    xgb = xgboost.XGBRegressor(**param_xgb_grid)\n",
    "\n",
    "    xgb.fit(X_train, y_train,\n",
    "            eval_set = [(X_test, y_test)], #Eval set only to check for overfitting etc. and necessary for early_stopping_rounds!\n",
    "            verbose = 0, # how many iteration steps are displayed. True -> show all \n",
    "            )\n",
    "            \n",
    "    # make predictions for test data based on the best test model determined before\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    mae_xgb_test = round(mean_absolute_error(y_test, y_pred_xgb), 4)\n",
    "    return mae_xgb_test\n",
    " \n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study_xgb = optuna.create_study(direction='minimize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    " \n",
    "print('Number of finished trials:', len(study_xgb.trials))\n",
    "print(f'Best trial: #{study_xgb.best_trial.number} {study_xgb.best_trial.values[0]}', study_xgb.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model stacking (ensemble)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 time series split für 80% machen. für alle außer dem ersten split die test pred (spalte 2), den dazugehoerigen index der test range (spalte 1) und die actual wert der index range (splate 3) in ein df packen. die splits untereinander packen  \n",
    "2 das modell trainieren und für holdout predicten  \n",
    "https://www.kaggle.com/code/sarmat/lgbm-stacking-example/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "regressors = [('gbm1', lightgbm.LGBMRegressor(**param)),\n",
    "                ('gbm2', lightgbm.LGBMRegressor(**param))]\n",
    "reg_stacked = StackingRegressor(estimators=regressors,\n",
    "                        final_estimator=lightgbm.LGBMRegressor(**param),\n",
    "                        passthrough=True)\n",
    "\n",
    "reg_stacked.fit(X_train, y_train)\n",
    "y_pred_stacked = reg_stacked.predict(X_test)\n",
    "mae_stacked_test = round(mean_absolute_error(y_test, y_pred_stacked), 4)\n",
    "mae_rf_test, mae_lgbm_test, mae_stacked_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time series forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sktime.org/en/stable/examples/01_forecasting.html#1.2.6-Panel-forecasts-and-hierarchical-forecasts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3e381f551a8bfb0e9b2340a6eefa2c96f51c492f499559f7d264c6f3e48fb0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
